{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from openai import OpenAI\n",
    "import re\n",
    "import pprint\n",
    "from getting_examples import get_activation_data_for_feature\n",
    "\n",
    "def find_first_number(text):\n",
    "    # Return the first number in a string\n",
    "    match = re.search(r'\\b\\d+(\\.\\d+)?', text)\n",
    "    return match.group(0) if match else None\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "def predict_activations(feature_index, test_number=20, show_examples=0):\n",
    "    # Get and parse JSON data from the url corresponding to the requested feature\n",
    "    url = f\"https://www.neuronpedia.org/api/feature/gpt2-small/9-res-jb/{feature_index}\"\n",
    "    data = get_activation_data_for_feature(url)\n",
    "    explanation = data['explanations'][0]['description']\n",
    "\n",
    "    assert (len(data['examples']) >= (test_number + show_examples))\n",
    "\n",
    "    # Randomly select some sentences to use as examples and test data\n",
    "    random_indices = np.random.choice(len(data['examples']), size=test_number + show_examples, replace=False)\n",
    "    sentences = [{'sentence_string': ''.join(data['examples'][i]['tokens']), 'activation':  data['examples'][i]['maxValue'], 'max_index': data['examples'][i]['maxValueTokenIndex']} for i in random_indices]\n",
    "    example_sentences = sentences[:show_examples]\n",
    "    test_sentences = sentences[show_examples:] \n",
    "\n",
    "    highest_activation = data['examples'][0]['maxValue']\n",
    "\n",
    "    # Create a system prompt dependning on how many example sentences are provided\n",
    "    system_prompt = f'You are evaluating an english description of an autoencoder feature. The description should correspond to setences which result in high activation. The english description of the feature is: \"{explanation}\"\\n'\n",
    "\n",
    "    if show_examples:\n",
    "        system_prompt += 'Here are 20 examples of sentences and their corresponding activations:\\n '\n",
    "        for sentence in example_sentences:\n",
    "            system_prompt += f'Example: \"{sentence['sentence_string']}\", Activation: {sentence['activation']}\\n'\n",
    "        system_prompt += 'Use the provided samples and the provided description to predict the activation on a new sentence.'\n",
    "\n",
    "    else:\n",
    "        system_prompt += f'The value of the highest activation on the dataset is {highest_activation}. You must predict the activation on a new sentence based off of the provided description â€“ if the description matches the provided sentence, the activation may be closer to {highest_activation}, while if it does not match the activation will be nearly 0.'\n",
    "\n",
    "    system_prompt += '\\nYou MUST respond with ONLY a number and NO OTHER content.'\n",
    "\n",
    "    predictions = []\n",
    "\n",
    "    # Have the model predict activations on each test sentence\n",
    "    for sentence in test_sentences:\n",
    "        user_message = f'Please predict the activation on this sentence, responding with a number between 0 and {highest_activation}.\\n\\nSentence: \"{sentence['sentence_string']}\"'\n",
    "\n",
    "        completion = client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_message}\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        predicted = find_first_number(completion.choices[0].message.content)\n",
    "        # (true, pred)\n",
    "        predictions.append((sentence['activation'], predicted))\n",
    "\n",
    "    return predictions"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
