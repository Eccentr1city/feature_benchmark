{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from analyze_results import *\n",
    "from getting_examples import *\n",
    "from predict_activations import *\n",
    "from model_utils import *\n",
    "from utils import *\n",
    "import json\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/feature_benchmark/feat_bench/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gpt2-small into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "sae, model = load_sae_and_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2350.json sorted into 56 positive and 25 self_negative activations\n",
      "23251.json sorted into 58 positive and 25 self_negative activations\n",
      "11000.json sorted into 52 positive and 25 self_negative activations\n",
      "13627.json sorted into 50 positive and 25 self_negative activations\n",
      "21896.json sorted into 53 positive and 27 self_negative activations\n",
      "6332.json sorted into 44 positive and 25 self_negative activations\n",
      "2534.json sorted into 48 positive and 37 self_negative activations\n",
      "11263.json sorted into 55 positive and 25 self_negative activations\n",
      "8913.json sorted into 54 positive and 25 self_negative activations\n",
      "9532.json sorted into 54 positive and 29 self_negative activations\n",
      "5128.json sorted into 60 positive and 25 self_negative activations\n",
      "5157.json sorted into 58 positive and 25 self_negative activations\n",
      "15162.json sorted into 58 positive and 25 self_negative activations\n",
      "12092.json sorted into 53 positive and 25 self_negative activations\n",
      "19697.json sorted into 60 positive and 27 self_negative activations\n",
      "15570.json sorted into 49 positive and 36 self_negative activations\n",
      "21983.json sorted into 29 positive and 30 self_negative activations\n",
      "3230.json sorted into 55 positive and 25 self_negative activations\n",
      "20780.json sorted into 5 positive and 74 self_negative activations\n",
      "10322.json sorted into 58 positive and 25 self_negative activations\n",
      "7428.json sorted into 43 positive and 25 self_negative activations\n",
      "10949.json sorted into 55 positive and 25 self_negative activations\n",
      "11451.json sorted into 49 positive and 25 self_negative activations\n",
      "16697.json sorted into 54 positive and 25 self_negative activations\n",
      "6750.json sorted into 46 positive and 26 self_negative activations\n",
      "19453.json sorted into 53 positive and 25 self_negative activations\n",
      "23607.json sorted into 55 positive and 27 self_negative activations\n",
      "1346.json sorted into 63 positive and 25 self_negative activations\n",
      "4730.json sorted into 60 positive and 25 self_negative activations\n",
      "21772.json sorted into 54 positive and 25 self_negative activations\n",
      "11817.json sorted into 44 positive and 26 self_negative activations\n",
      "20963.json sorted into 56 positive and 20 self_negative activations\n",
      "17386.json sorted into 45 positive and 25 self_negative activations\n",
      "20351.json sorted into 51 positive and 25 self_negative activations\n",
      "20820.json sorted into 54 positive and 26 self_negative activations\n",
      "3096.json sorted into 54 positive and 26 self_negative activations\n",
      "4634.json sorted into 50 positive and 26 self_negative activations\n",
      "2830.json sorted into 28 positive and 52 self_negative activations\n",
      "11212.json sorted into 64 positive and 25 self_negative activations\n",
      "16183.json sorted into 57 positive and 28 self_negative activations\n",
      "10404.json sorted into 0 positive and 81 self_negative activations\n",
      "8064.json sorted into 49 positive and 27 self_negative activations\n",
      "14882.json sorted into 60 positive and 25 self_negative activations\n",
      "6448.json sorted into 55 positive and 25 self_negative activations\n",
      "14583.json sorted into 41 positive and 25 self_negative activations\n",
      "1103.json sorted into 48 positive and 27 self_negative activations\n",
      "10075.json sorted into 63 positive and 26 self_negative activations\n",
      "5625.json sorted into 40 positive and 25 self_negative activations\n",
      "9760.json sorted into 52 positive and 25 self_negative activations\n",
      "3594.json sorted into 51 positive and 25 self_negative activations\n",
      "20189.json sorted into 61 positive and 25 self_negative activations\n",
      "2004.json sorted into 52 positive and 31 self_negative activations\n",
      "11264.json sorted into 60 positive and 25 self_negative activations\n",
      "8685.json sorted into 63 positive and 17 self_negative activations\n",
      "16693.json sorted into 54 positive and 26 self_negative activations\n",
      "7476.json sorted into 47 positive and 25 self_negative activations\n",
      "16596.json sorted into 58 positive and 25 self_negative activations\n",
      "11799.json sorted into 31 positive and 25 self_negative activations\n",
      "13133.json sorted into 52 positive and 25 self_negative activations\n",
      "9658.json sorted into 45 positive and 25 self_negative activations\n",
      "1202.json sorted into 36 positive and 25 self_negative activations\n",
      "12694.json sorted into 48 positive and 25 self_negative activations\n",
      "14524.json sorted into 27 positive and 25 self_negative activations\n",
      "4036.json sorted into 64 positive and 11 self_negative activations\n",
      "19899.json sorted into 0 positive and 77 self_negative activations\n",
      "4679.json sorted into 56 positive and 28 self_negative activations\n",
      "14073.json sorted into 60 positive and 25 self_negative activations\n",
      "14372.json sorted into 59 positive and 25 self_negative activations\n",
      "14610.json sorted into 38 positive and 26 self_negative activations\n",
      "15500.json sorted into 57 positive and 26 self_negative activations\n",
      "21032.json sorted into 51 positive and 25 self_negative activations\n",
      "752.json sorted into 50 positive and 25 self_negative activations\n",
      "18083.json sorted into 50 positive and 25 self_negative activations\n",
      "7739.json sorted into 55 positive and 25 self_negative activations\n",
      "11606.json sorted into 59 positive and 25 self_negative activations\n",
      "3197.json sorted into 53 positive and 27 self_negative activations\n",
      "14169.json sorted into 52 positive and 26 self_negative activations\n",
      "19484.json sorted into 54 positive and 20 self_negative activations\n",
      "22719.json sorted into 54 positive and 28 self_negative activations\n",
      "8728.json sorted into 51 positive and 25 self_negative activations\n",
      "7104.json sorted into 58 positive and 26 self_negative activations\n",
      "14931.json sorted into 9 positive and 78 self_negative activations\n",
      "22832.json sorted into 48 positive and 30 self_negative activations\n",
      "2858.json sorted into 52 positive and 25 self_negative activations\n",
      "9002.json sorted into 61 positive and 25 self_negative activations\n",
      "536.json sorted into 53 positive and 26 self_negative activations\n",
      "7585.json sorted into 50 positive and 25 self_negative activations\n",
      "17533.json sorted into 50 positive and 25 self_negative activations\n",
      "428.json sorted into 51 positive and 26 self_negative activations\n",
      "19505.json sorted into 59 positive and 25 self_negative activations\n",
      "6769.json sorted into 50 positive and 25 self_negative activations\n",
      "2726.json sorted into 53 positive and 27 self_negative activations\n",
      "13410.json sorted into 56 positive and 25 self_negative activations\n",
      "22202.json sorted into 52 positive and 27 self_negative activations\n",
      "3509.json sorted into 54 positive and 25 self_negative activations\n",
      "9579.json sorted into 24 positive and 54 self_negative activations\n",
      "681.json sorted into 40 positive and 25 self_negative activations\n",
      "22138.json sorted into 60 positive and 26 self_negative activations\n",
      "21380.json sorted into 42 positive and 25 self_negative activations\n",
      "15824.json sorted into 36 positive and 25 self_negative activations\n"
     ]
    }
   ],
   "source": [
    "recompute_directory_activations('6-res-jb_subset_100', model, sae, recompute=False, re_sort=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mentions of financial funding through grants\n",
      " published this spring, was funded through a grant from NHTSA and conducted through the\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 49.51050567626953, 0.1973066926002502, 0, 0, 0, 0, 0, 0, 0]\n",
      "I. will receive a three-year grant from the Massachusetts Service Alliance that will place\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 48.00002670288086, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      " has devolved into a âĢľknife fight,âĢĿ writing on Twitter that he\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      " but Orlando made it clear that if it flags again for whatever reason, Jefferson will find\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "feat_id = 1\n",
    "\n",
    "description, pos_examples, neg_examples, highest_activation = get_pos_neg_examples(feat_id, layer=6, basis='res-jb', num_pos=2, num_neg=2, neg_type='others', randomize_pos_examples=False)\n",
    "print(description)\n",
    "\n",
    "max_indices = [pos_examples[i]['max_value_token_index'] + 1 for i in range(len(pos_examples))] + [9 for i in range(len(neg_examples))]\n",
    "strings = [pos_examples[i]['sentence_string'] for i in range(len(pos_examples))] + [neg_examples[i]['sentence_string'] for i in range(len(neg_examples))]\n",
    "\n",
    "for pos in pos_examples:\n",
    "    print(pos['sentence_string'])\n",
    "    print(pos['values'])\n",
    "\n",
    "for neg in neg_examples:\n",
    "    print(neg['sentence_string'])\n",
    "    print(neg['values'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.         48.49956131  1.33336258  0.\n",
      "  0.          0.          0.          0.          0.          0.        ]\n",
      "[ 0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.         42.76519775  0.          0.\n",
      "  0.          0.          0.          0.          0.          0.        ]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "pre_acts, inner_acts, post_acts = get_sae_activations(model, sae, strings)\n",
    "\n",
    "for inner_act in inner_acts:\n",
    "    x = np.array(inner_act)\n",
    "    print(x[:,feat_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regular losses:\n",
      " published this spring, was funded through a grant from NHTSA and conducted through the (4.1803): 13.6845 6.9317 6.7337 2.1646 5.5099 5.8693 3.7500 1.0739 2.1365 0.1572 6.3267 4.8857 0.0050 2.3500 5.8504 2.4335 1.2026\n",
      "I. will receive a three-year grant from the Massachusetts Service Alliance that will place (4.7467): 3.9997 6.1135 11.2789 7.5890 1.7388 7.5961 0.6220 2.4118 5.1721 1.0106 0.4074 5.7994 9.1498 5.7121 3.7558 0.5996 7.7381\n",
      " has devolved into a âĢľknife fight,âĢĿ writing on Twitter that he (5.2934): 9.2262 9.6372 0.7124 0.4154 0.7375 13.1011 3.4074 6.8675 5.2687 2.0278 5.5630 14.7221 5.4033 2.3048 11.7609 3.5082 1.2562 0.5191 5.8215 12.7050 2.8637 3.5894 3.3287 2.2940\n",
      " but Orlando made it clear that if it flags again for whatever reason, Jefferson will find (5.1637): 9.4798 11.8629 6.9563 1.6820 1.4295 1.3284 3.9408 3.4473 11.8570 6.4385 3.4611 7.7009 0.2480 0.7260 10.1121 1.6435 5.4686\n",
      "SAE losses:\n",
      " published this spring, was funded through a grant from NHTSA and conducted through the (4.1995): 13.7159 5.8250 7.5830 1.0363 5.8370 7.0606 3.2471 1.2248 2.1267 0.3422 6.6113 4.4166 0.2100 2.4070 5.8228 2.7563 1.1680\n",
      "I. will receive a three-year grant from the Massachusetts Service Alliance that will place (4.7523): 4.0963 5.9176 10.0126 7.4673 1.9837 7.4549 0.4112 1.9489 5.1028 1.0288 0.6698 6.3484 9.1827 6.5538 4.3308 0.8622 7.4177\n",
      " has devolved into a âĢľknife fight,âĢĿ writing on Twitter that he (5.5585): 9.2599 9.4927 1.3284 0.6745 0.6776 12.7107 3.0418 6.9685 4.8998 2.9369 4.9045 14.0943 6.7202 2.3130 10.0201 4.6600 2.3914 2.4021 6.7871 12.6831 3.2904 4.4149 4.1765 2.5547\n",
      " but Orlando made it clear that if it flags again for whatever reason, Jefferson will find (5.1745): 9.4950 12.0049 6.9759 2.1069 1.2028 1.0289 4.1152 3.5979 11.8669 6.4256 4.1042 5.9100 0.2713 0.8290 10.1469 2.2904 5.5941\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zeros losses:\n",
      " published this spring, was funded through a grant from NHTSA and conducted through the (8.6929): 9.7256 7.3141 10.6736 2.3919 7.9510 12.9913 5.9910 4.6239 10.9653 6.5388 10.9766 15.3514 19.6931 2.3378 9.0870 5.9910 5.1758\n",
      "I. will receive a three-year grant from the Massachusetts Service Alliance that will place (9.3040): 12.6561 1.9816 8.2481 10.3467 4.6239 8.8132 6.0656 14.0043 10.9653 6.5388 5.1758 14.6507 13.7828 17.5590 5.6262 8.2481 8.8816\n",
      " has devolved into a âĢľknife fight,âĢĿ writing on Twitter that he (13.3899): 6.8246 9.6344 13.1302 7.5066 4.6239 12.0840 22.9173 16.9512 22.9173 16.9512 19.7396 21.1252 12.1505 2.3919 17.0953 16.9512 22.9173 16.9512 19.8813 11.2551 3.5308 9.3789 5.6262 8.8215\n",
      " but Orlando made it clear that if it flags again for whatever reason, Jefferson will find (8.4580): 6.8127 14.2523 6.8156 5.6377 10.0778 5.6262 8.4823 5.6377 13.4297 6.8230 4.9349 9.0796 9.1752 2.3919 16.8460 8.2481 9.5161\n"
     ]
    }
   ],
   "source": [
    "# Get model's loss on strings\n",
    "regular_losses = get_vanilla_loss(model, sae, strings)\n",
    "print(pretty_losses_fmt(\"Regular\", strings, regular_losses))\n",
    "\n",
    "# Get model's loss on strings using SAE reconstructed activations\n",
    "sae_losses = get_vanilla_loss(model, sae, strings, with_sae_replacement=True)\n",
    "print(pretty_losses_fmt(\"SAE\", strings, sae_losses))\n",
    "\n",
    "# Loss with all features ablated\n",
    "precomputed_zeros = [[[0.0] * len(l) for l in seq] for seq in inner_acts]\n",
    "zeros_losses = get_recons_loss_from_predicted_values(model, sae, strings, precomputed_zeros)\n",
    "print(pretty_losses_fmt(\"Zeros\", strings, zeros_losses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAE feature 1 ablated losses:\n",
      " published this spring, was funded through a grant from NHTSA and conducted through the (4.2348): 13.7159 5.8250 7.5830 1.0363 5.8370 7.0606 3.2471 1.2248 2.1267 0.7712 6.5461 4.4802 0.2106 2.4924 5.8819 2.7817 1.1709\n",
      "I. will receive a three-year grant from the Massachusetts Service Alliance that will place (4.7978): 4.0963 5.9176 10.0126 7.4673 1.9837 7.4549 0.4112 1.9489 5.1028 1.6349 0.8448 6.5888 9.1750 6.6881 4.3267 0.9515 6.9573\n",
      " has devolved into a âĢľknife fight,âĢĿ writing on Twitter that he (5.5585): 9.2599 9.4927 1.3284 0.6745 0.6776 12.7107 3.0418 6.9685 4.8998 2.9369 4.9045 14.0943 6.7202 2.3130 10.0201 4.6600 2.3914 2.4021 6.7871 12.6831 3.2904 4.4149 4.1765 2.5547\n",
      " but Orlando made it clear that if it flags again for whatever reason, Jefferson will find (5.1745): 9.4950 12.0049 6.9759 2.1069 1.2028 1.0289 4.1152 3.5979 11.8669 6.4256 4.1042 5.9100 0.2713 0.8290 10.1469 2.2904 5.5941\n",
      "[0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         1.33336258 0.\n",
      " 0.         0.         0.         0.         0.         0.        ]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.43, -0.07, 0.06, 0.0, 0.09, 0.06, 0.03, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.61, 0.17, 0.24, -0.01, 0.13, -0.0, 0.09, -0.46], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]]\n"
     ]
    }
   ],
   "source": [
    "# Get model's loss on strings using SAE with selected feature ablated\n",
    "replacements = [0 for string in strings]\n",
    "ablated_inner_acts = replace_max_feature_activation(inner_acts, feat_id, max_indices, replacements)\n",
    "ablated_sae_losses = get_recons_loss_from_predicted_values(model, sae, strings, ablated_inner_acts)\n",
    "print(pretty_losses_fmt(f\"SAE feature {feat_id} ablated\", strings, ablated_sae_losses))\n",
    "\n",
    "for inner_act in ablated_inner_acts:\n",
    "    x = np.array(inner_act)\n",
    "    print(x[:,feat_id])\n",
    "\n",
    "# Print how much loss changes after ablating selected feature\n",
    "difference = elementwise_difference(sae_losses, ablated_sae_losses)\n",
    "rounded_difference = [[round(elem, 2) for elem in sublist] for sublist in difference]\n",
    "print(rounded_difference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2350, 23251, 11000, 13627, 21896, 6332, 2534, 11263, 8913, 9532, 5128, 5157, 15162, 12092, 19697, 15570, 21983, 3230, 20780, 10322, 7428, 10949, 11451, 16697, 6750, 19453, 23607, 1346, 4730, 21772, 11817, 20963, 17386, 20351, 20820, 3096, 4634, 2830, 11212, 16183, 10404, 8064, 14882, 6448, 14583, 1103, 10075, 5625, 9760, 3594, 20189, 2004, 11264, 8685, 16693, 7476, 16596, 11799, 13133, 9658, 1202, 12694, 14524, 4036, 19899, 4679, 14073, 14372, 14610, 15500, 21032, 752, 18083, 7739, 11606, 3197, 14169, 19484, 22719, 8728, 7104, 14931, 22832, 2858, 9002, 536, 7585, 17533, 428, 19505, 6769, 2726, 13410, 22202, 3509, 9579, 681, 22138, 21380, 15824]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "indices = list(map(int, np.random.choice(24576, size=100, replace=False)))\n",
    "print(indices)\n",
    "# copy_files_by_list(indices, 'gpt2-small-organized/6-res-jb', '6-res-jb_subset_100')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run an experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are evaluating an english description of an autoencoder feature. The description should correspond to sentences which result in high activation. The english description of the feature is: \"phrases indicating a numerical quantity of additional items or time\"\n",
      "The feature will tend to have zero activation on most tokens, but may activate highly on one or a few tokens in the sentence that correspond to the provided description.\n",
      "The value of the highest activation on the dataset is 41.52. Most tokens have an activation of zero, and a few tokens that match the provided description may have higher activations (somewhere between 0 and 41.52). You must predict the activations for each token a new sentence based off of the provided description. \n",
      "You MUST respond with a list of numbers, one for each token in the sequence, and NO OTHER content.\n",
      "Submitted 1 of 2 tasks. Been running for 5 seconds\n",
      "Please predict the activation on this sentence,responding with a list of 17 numbers between 0 and 41.52.\n",
      "Sentence: \" president in prison for up to 30 days more.ĊĊThe former strongman's\"\n",
      "Tokens:\n",
      " president\n",
      " in\n",
      " prison\n",
      " for\n",
      " up\n",
      " to\n",
      " 30\n",
      " days\n",
      " more\n",
      ".\n",
      "Ċ\n",
      "Ċ\n",
      "The\n",
      " former\n",
      " strong\n",
      "man\n",
      "'s\n",
      "Remember, the english description of the feature is: \"phrases indicating a numerical quantity of additional items or time\"\n",
      "Model response: 0, 0, 0, 0, 0, 0, 41.52, 41.52, 41.52, 0, 0, 0, 0, 0, 0, 0\n",
      "Parsed response: None\n",
      "WARNING: Resampling\n",
      "Model response: 0, 0, 0, 0, 0, 8.22, 26.91, 33.75, 37.63, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "Parsed response: [0.0, 0.0, 0.0, 0.0, 0.0, 8.22, 26.91, 33.75, 37.63, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Model response: 0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "31.45\n",
      "31.02\n",
      "38.61\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "Parsed response: None\n",
      "WARNING: Resampling\n",
      "WARNING: padding prediction with 1 zeros\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 16.83867073059082, 0, 0, 0, 0, 0, 0, 0, 0] [0.0, 0.0, 0.0, 0.0, 0.0, 2.74, 16.12666666666667, 12.476666666666667, 13.726666666666667, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "You are evaluating an english description of an autoencoder feature. The description should correspond to sentences which result in high activation. The english description of the feature is: \"references to the target audience or readership\"\n",
      "The feature will tend to have zero activation on most tokens, but may activate highly on one or a few tokens in the sentence that correspond to the provided description.\n",
      "The value of the highest activation on the dataset is 45.17. Most tokens have an activation of zero, and a few tokens that match the provided description may have higher activations (somewhere between 0 and 45.17). You must predict the activations for each token a new sentence based off of the provided description. \n",
      "You MUST respond with a list of numbers, one for each token in the sequence, and NO OTHER content.\n",
      "Please predict the activation on this sentence,responding with a list of 17 numbers between 0 and 41.52.\n",
      "Sentence: \" be, because I am only one of more than fifteen thousand people at Get Motivated\"\n",
      "Tokens:\n",
      " be\n",
      ",\n",
      " because\n",
      " I\n",
      " am\n",
      " only\n",
      " one\n",
      " of\n",
      " more\n",
      " than\n",
      " fifteen\n",
      " thousand\n",
      " people\n",
      " at\n",
      " Get\n",
      " Mot\n",
      "ivated\n",
      "Remember, the english description of the feature is: \"phrases indicating a numerical quantity of additional items or time\"\n",
      "Model response:Submitted 2 of 2 tasks. Been running for 9 seconds\n",
      " 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 41.52, 41.52, 0, 0, 0, 0, 0\n",
      "Parsed response: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 41.52, 41.52, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Model response: 0, 0, 0, 0, 0, 0, 0, 0, 0, 41.52, 0, 41.52, 0, 0, 0, 0, 0\n",
      "Parsed response: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 41.52, 0.0, 41.52, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Model response: 0, 0, 0, 0, 0, 0, 0, 0, 0, 41.52, 41.52, 41.52, 41.52, 0, 0, 0, 0\n",
      "Parsed response: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 41.52, 41.52, 41.52, 41.52, 0.0, 0.0, 0.0, 0.0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 8.929347038269043, 0, 0, 0, 0, 0, 0, 0, 0] [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 27.680000000000003, 27.680000000000003, 41.52, 13.840000000000002, 0.0, 0.0, 0.0, 0.0]\n",
      "Please predict the activation on this sentence,responding with a list of 17 numbers between 0 and 45.17.\n",
      "Sentence: \" Combat for the first time to a live audience.ĊĊThe two weeks before the\"\n",
      "Tokens:\n",
      " Combat\n",
      " for\n",
      " the\n",
      " first\n",
      " time\n",
      " to\n",
      " a\n",
      " live\n",
      " audience\n",
      ".\n",
      "Ċ\n",
      "Ċ\n",
      "The\n",
      " two\n",
      " weeks\n",
      " before\n",
      " the\n",
      "Remember, the english description of the feature is: \"references to the target audience or readership\"\n",
      "Model response: 0, 0, 0, 0, 0, 0, 0, 28.32, 45.17, 0, 0, 0, 0, 0, 0, 0\n",
      "Parsed response: None\n",
      "WARNING: Resampling\n",
      "Please predict the activation on this sentence,responding with a list of 17 numbers between 0 and 41.52.\n",
      "Sentence: \" any weird noises, and wait for someone more important than you to die.ĊĊ\"\n",
      "Tokens:\n",
      " any\n",
      " weird\n",
      " noises\n",
      ",\n",
      " and\n",
      " wait\n",
      " for\n",
      " someone\n",
      " more\n",
      " important\n",
      " than\n",
      " you\n",
      " to\n",
      " die\n",
      ".\n",
      "Ċ\n",
      "Ċ\n",
      "Remember, the english description of the feature is: \"phrases indicating a numerical quantity of additional items or time\"\n",
      "Model response: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 41.52, 0, 0, 0\n",
      "Parsed response: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 41.52, 0.0, 0.0, 0.0]\n",
      "Model response: 0, 0, 0, 0, 0, 0, 0, 0, 0, 41.52, 0, 0, 0, 0, 0, 0, 0\n",
      "Parsed response: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 41.52, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Model response: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 41.52, 0, 0, 0, 0\n",
      "Parsed response: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 41.52, 0.0, 0.0, 0.0, 0.0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 8.909917831420898, 0, 0, 0, 0, 0, 0, 0, 0] [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 13.840000000000002, 0.0, 0.0, 13.840000000000002, 13.840000000000002, 0.0, 0.0, 0.0]\n",
      "WARNING: padding prediction with 1 zeros\n",
      "Model response: 0, 0, 0, 0, 0, 0, 0, 45.17, 45.17, 0, 0, 0, 0, 0, 0, 0\n",
      "Parsed response: None\n",
      "WARNING: Resampling\n",
      "Please predict the activation on this sentence,responding with a list of 17 numbers between 0 and 41.52.\n",
      "Sentence: \"oevsky's parents subsequently had six more children: Varvara (1822\"\n",
      "Tokens:\n",
      "o\n",
      "ev\n",
      "sky\n",
      "'s\n",
      " parents\n",
      " subsequently\n",
      " had\n",
      " six\n",
      " more\n",
      " children\n",
      ":\n",
      " Var\n",
      "v\n",
      "ara\n",
      " (\n",
      "18\n",
      "22\n",
      "Remember, the english description of the feature is: \"phrases indicating a numerical quantity of additional items or time\"\n",
      "Model response: 0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "41.52\n",
      "41.52\n",
      "41.52\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "41.52\n",
      "41.52\n",
      "Parsed response: None\n",
      "WARNING: Resampling\n",
      "WARNING: padding prediction with 1 zeros\n",
      "Model response: 0, 0, 0, 0, 0, 0, 0, 17.28, 41.52, 41.52, 0, 0, 0, 0, 41.52, 41.52, 0\n",
      "Parsed response: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 17.28, 41.52, 41.52, 0.0, 0.0, 0.0, 0.0, 41.52, 41.52, 0.0]\n",
      "Model response: 0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "6.31\n",
      "41.52\n",
      "41.52\n",
      "41.52\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "41.52\n",
      "41.52\n",
      "0\n",
      "Parsed response: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.31, 41.52, 41.52, 41.52, 0.0, 0.0, 0.0, 0.0, 41.52, 41.52, 0.0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 34.22396469116211, 0, 0, 0, 0, 0, 0, 0, 0] [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.103333333333333, 33.440000000000005, 27.680000000000003, 41.52, 0.0, 0.0, 0.0, 0.0, 27.680000000000003, 41.52, 0.0]\n",
      "Model response: 0, 0, 0, 0, 0, 0, 0, 45.17, 45.17, 0, 0, 45.17, 0, 0, 0, 0, 0\n",
      "Parsed response: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 45.17, 45.17, 0.0, 0.0, 45.17, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 36.86307525634766, 0, 0, 0, 0, 0, 0, 0, 0] [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 38.86333333333334, 44.39666666666667, 0.0, 0.0, 15.056666666666667, 0.0, 0.0, 15.056666666666667, 0.0, 0.0]\n",
      "Please predict the activation on this sentence,responding with a list of 17 numbers between 0 and 45.17.\n",
      "Sentence: \" accommodation on a site in her south Dublin constituency would be \"a waste of valuable resources\"\n",
      "Tokens:\n",
      " accommodation\n",
      " on\n",
      " a\n",
      " site\n",
      " in\n",
      " her\n",
      " south\n",
      " Dublin\n",
      " constituency\n",
      " would\n",
      " be\n",
      " \"\n",
      "a\n",
      " waste\n",
      " of\n",
      " valuable\n",
      " resources\n",
      "Remember, the english description of the feature is: \"references to the target audience or readership\"\n",
      "Model response: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 24.51, 0, 0, 0\n",
      "Parsed response: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 24.51, 0.0, 0.0, 0.0]\n",
      "Model response: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 35.12, 0, 0, 45.17, 0\n",
      "Parsed response: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 35.12, 0.0, 0.0, 45.17, 0.0]\n",
      "Model response: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 15.76, 0, 0, 0\n",
      "Parsed response: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 15.76, 0.0, 0.0, 0.0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 5.005291938781738, 0, 0, 0, 0, 0, 0, 0, 0] [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.706666666666665, 13.423333333333334, 0.0, 15.056666666666667, 0.0]\n",
      "Please predict the activation on this sentence,responding with a list of 17 numbers between 0 and 41.52.\n",
      "Sentence: \" a.m. The controller gets off work at 3 p.m. after the\"\n",
      "Tokens:\n",
      " a\n",
      ".\n",
      "m\n",
      ".\n",
      " The\n",
      " controller\n",
      " gets\n",
      " off\n",
      " work\n",
      " at\n",
      " 3\n",
      " p\n",
      ".\n",
      "m\n",
      ".\n",
      " after\n",
      " the\n",
      "Remember, the english description of the feature is: \"phrases indicating a numerical quantity of additional items or time\"\n",
      "Model response: 0, 0, 0, 0, 0, 0, 0, 0, 0, 22.36, 0, 0, 0, 0, 0, 0, 0\n",
      "Parsed response: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.36, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Model response: 0, 0, 0, 0, 0, 0, 0, 0, 0, 41.52, 0, 0, 0, 0, 0, 0, 0\n",
      "Parsed response: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 41.52, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Model response: 0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "41.52\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "Parsed response: None\n",
      "WARNING: Resampling\n",
      "Please predict the activation on this sentence,responding with a list of 17 numbers between 0 and 45.17.\n",
      "Sentence: \" to Rs 600 cr.The film fascinated audiences because of its visual effects. The fact\"\n",
      "Tokens:\n",
      " to\n",
      " Rs\n",
      " 600\n",
      " cr\n",
      ".\n",
      "The\n",
      " film\n",
      " fascinated\n",
      " audiences\n",
      " because\n",
      " of\n",
      " its\n",
      " visual\n",
      " effects\n",
      ".\n",
      " The\n",
      " fact\n",
      "Remember, the english description of the feature is: \"references to the target audience or readership\"\n",
      "Model response: 0, 0, 0, 0, 0, 0, 0, 25.75, 45.17, 0, 0, 0, 0, 0, 0, 0\n",
      "Parsed response: None\n",
      "WARNING: Resampling\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 35.13333333333333, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "WARNING: padding prediction with 1 zeros\n",
      "Model response: 0, 0, 0, 0, 0, 0, 0, 32.14, 45.17, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "Parsed response: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 32.14, 45.17, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Model response: 0, 0, 0, 0, 0, 0, 0, 29.21, 45.17, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "Parsed response: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.21, 45.17, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 17.6229248046875, 0, 0, 0, 0, 0, 0, 0, 0] [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 31.156666666666666, 45.169999999999995, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Please predict the activation on this sentence,responding with a list of 17 numbers between 0 and 41.52.\n",
      "Sentence: \"PL has increased the number of employees in its legal and risk departments by 41% since\"\n",
      "Tokens:\n",
      "PL\n",
      " has\n",
      " increased\n",
      " the\n",
      " number\n",
      " of\n",
      " employees\n",
      " in\n",
      " its\n",
      " legal\n",
      " and\n",
      " risk\n",
      " departments\n",
      " by\n",
      " 41\n",
      "%\n",
      " since\n",
      "Remember, the english description of the feature is: \"phrases indicating a numerical quantity of additional items or time\"\n",
      "Model response: 0\n",
      "0\n",
      "0\n",
      "0\n",
      "41.52\n",
      "0\n",
      "41.52\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "41.52\n",
      "41.52\n",
      "41.52\n",
      "0\n",
      "Parsed response: [0.0, 0.0, 0.0, 0.0, 41.52, 0.0, 41.52, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 41.52, 41.52, 41.52, 0.0]\n",
      "Model response: 0\n",
      "0\n",
      "0\n",
      "0\n",
      "17.28\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "41.52\n",
      "41.52\n",
      "0\n",
      "Parsed response: None\n",
      "WARNING: Resampling\n",
      "Please predict the activation on this sentence,responding with a list of 17 numbers between 0 and 45.17.\n",
      "Sentence: \" but she is perhaps best known to Western audiences for her feature-film roles in 1997\"\n",
      "Tokens:\n",
      " but\n",
      " she\n",
      " is\n",
      " perhaps\n",
      " best\n",
      " known\n",
      " to\n",
      " Western\n",
      " audiences\n",
      " for\n",
      " her\n",
      " feature\n",
      "-\n",
      "film\n",
      " roles\n",
      " in\n",
      " 1997\n",
      "Remember, the english description of the feature is: \"references to the target audience or readership\"\n",
      "Model response: 0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "45.17\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "Parsed response: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 45.17, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Model response: 0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "22.61\n",
      "22.61\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "Parsed response: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.61, 22.61, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Model response: 0, 0, 0, 0, 0, 0, 0, 0, 19.62, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "Parsed response: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 19.62, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 20.7180233001709, 0, 0, 0, 0, 0, 0, 0, 0] [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.133333333333336, 7.536666666666666, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Model response: 0\n",
      "0\n",
      "0\n",
      "0\n",
      "41.52\n",
      "0\n",
      "41.52\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "41.52\n",
      "41.52\n",
      "0\n",
      "0\n",
      "Parsed response: [0.0, 0.0, 0.0, 0.0, 41.52, 0.0, 41.52, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 41.52, 41.52, 0.0, 0.0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [0.0, 0.0, 0.0, 0.0, 39.083333333333336, 0.0, 27.680000000000003, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 41.52, 41.52, 13.840000000000002, 0.0]\n",
      "Please predict the activation on this sentence,responding with a list of 17 numbers between 0 and 41.52.\n",
      "Sentence: \" Germany Spring, Planetkey Dynamics have announced their first roster change since bringing in four new\"\n",
      "Tokens:\n",
      " Germany\n",
      " Spring\n",
      ",\n",
      " Planet\n",
      "key\n",
      " Dynamics\n",
      " have\n",
      " announced\n",
      " their\n",
      " first\n",
      " roster\n",
      " change\n",
      " since\n",
      " bringing\n",
      " in\n",
      " four\n",
      " new\n",
      "Remember, the english description of the feature is: \"phrases indicating a numerical quantity of additional items or time\"\n",
      "Model response: 0, 0, 0, 0, 0, 0, 0, 0, 0, 16.23, 0, 0, 0, 0, 41.52, 16.23, 0\n",
      "Parsed response: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 16.23, 0.0, 0.0, 0.0, 0.0, 41.52, 16.23, 0.0]\n",
      "Model response: 0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "41.52\n",
      "0\n",
      "0\n",
      "Parsed response: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 41.52, 0.0, 0.0]\n",
      "Model response: 0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "41.52\n",
      "0\n",
      "Parsed response: None\n",
      "WARNING: Resampling\n",
      "Please predict the activation on this sentence,responding with a list of 17 numbers between 0 and 45.17.\n",
      "Sentence: \"t know. We just kind of hang out, I guess we havenâĢĻt\"\n",
      "Tokens:\n",
      "t\n",
      " know\n",
      ".\n",
      " We\n",
      " just\n",
      " kind\n",
      " of\n",
      " hang\n",
      " out\n",
      ",\n",
      " I\n",
      " guess\n",
      " we\n",
      " haven\n",
      "âĢ\n",
      "Ļ\n",
      "t\n",
      "Remember, the english description of the feature is: \"references to the target audience or readership\"\n",
      "Model response: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 45.17, 0\n",
      "Parsed response: None\n",
      "WARNING: Resampling\n",
      "Model response: 0, 0, 0, 11.24, 0, 0, 0, 0, 0, 0, 0, 0, 11.75, 0, 0, 0, 0\n",
      "Parsed response: [0.0, 0.0, 0.0, 11.24, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.75, 0.0, 0.0, 0.0, 0.0]\n",
      "Model response: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 45.17, 0, 0, 0\n",
      "Parsed response: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 45.17, 0.0, 0.0, 0.0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [0.0, 0.0, 0.0, 3.7466666666666666, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 18.973333333333333, 15.056666666666667, 0.0, 0.0, 0.0]\n",
      "Please predict the activation on this sentence,responding with a list of 17 numbers between 0 and 45.17.\n",
      "Sentence: \" time, âĢľWhat do you actually eat?âĢĿ The post, aptly titled\"\n",
      "Tokens:\n",
      " time\n",
      ",\n",
      " âĢ\n",
      "ľ\n",
      "What\n",
      " do\n",
      " you\n",
      " actually\n",
      " eat\n",
      "?\n",
      "âĢ\n",
      "Ŀ\n",
      " The\n",
      " post\n",
      ",\n",
      " aptly\n",
      " titled\n",
      "Remember, the english description of the feature is: \"references to the target audience or readership\"\n",
      "Model response: 0, 0, 0, 0, 0, 0, 0, 0, 30.12, 0, 0, 27.65, 0, 0, 0, 0\n",
      "Parsed response: None\n",
      "WARNING: Resampling\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.41, 0.0, 0.0, 0.0, 13.840000000000002, 41.52, 5.41, 0.0]\n",
      "WARNING: padding prediction with 1 zeros\n",
      "Model response: 0, 0, 0, 0, 0, 0, 33.56, 0, 0, 0, 0, 0, 45.17, 0, 0, 0, 0\n",
      "Parsed response: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 33.56, 0.0, 0.0, 0.0, 0.0, 0.0, 45.17, 0.0, 0.0, 0.0, 0.0]\n",
      "Model response: 0, 0, 0, 0, 0, 0, 45.17, 43.22, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "Parsed response: None\n",
      "WARNING: Resampling\n",
      "Please predict the activation on this sentence,responding with a list of 17 numbers between 0 and 41.52.\n",
      "Sentence: \"etted against the evening sky. The steel giants begin moving almost inaudibly,\"\n",
      "Tokens:\n",
      "et\n",
      "ted\n",
      " against\n",
      " the\n",
      " evening\n",
      " sky\n",
      ".\n",
      " The\n",
      " steel\n",
      " giants\n",
      " begin\n",
      " moving\n",
      " almost\n",
      " in\n",
      "aud\n",
      "ibly\n",
      ",\n",
      "Remember, the english description of the feature is: \"phrases indicating a numerical quantity of additional items or time\"\n",
      "Model response: 0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "Parsed response: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Model response: 0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "Parsed response: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Model response: 0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "Parsed response: None\n",
      "WARNING: Resampling\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 32.32, 0.0, 0.0, 0.0, 0.0, 0.0, 15.056666666666667, 0.0, 0.0, 0.0, 0.0]\n",
      "Please predict the activation on this sentence,responding with a list of 17 numbers between 0 and 45.17.\n",
      "Sentence: \" overnight into Tuesday, two fatally. The newspaper says those shootings bring the total number shot\"\n",
      "Tokens:\n",
      " overnight\n",
      " into\n",
      " Tuesday\n",
      ",\n",
      " two\n",
      " fatally\n",
      ".\n",
      " The\n",
      " newspaper\n",
      " says\n",
      " those\n",
      " shootings\n",
      " bring\n",
      " the\n",
      " total\n",
      " number\n",
      " shot\n",
      "Remember, the english description of the feature is: \"references to the target audience or readership\"\n",
      "Model response: 0, 0, 0, 0, 0, 0, 0, 24.58, 0, 0, 0, 0, 0, 0, 42.73, 0\n",
      "Parsed response: None\n",
      "WARNING: Resampling\n",
      "Model response: 0, 0, 0, 0, 7.23, 0, 0, 18.45, 0, 0, 0, 0, 0, 0, 45.17, 0\n",
      "Parsed response: None\n",
      "WARNING: Resampling\n",
      "Model response: 0, 0, 0, 0, 0, 0, 0, 18.25, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "Parsed response: None\n",
      "WARNING: Resampling\n",
      "WARNING: padding prediction with 1 zeros\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 26.25666666666667, 0.0, 0.0, 0.0, 0.0, 7.723333333333334, 14.39, 0.0, 0.0, 0.0]\n",
      "Please predict the activation on this sentence,responding with a list of 17 numbers between 0 and 45.17.\n",
      "Sentence: \" through that hole in the hull? The one my security chief was just sucked out of\"\n",
      "Tokens:\n",
      " through\n",
      " that\n",
      " hole\n",
      " in\n",
      " the\n",
      " hull\n",
      "?\n",
      " The\n",
      " one\n",
      " my\n",
      " security\n",
      " chief\n",
      " was\n",
      " just\n",
      " sucked\n",
      " out\n",
      " of\n",
      "Remember, the english description of the feature is: \"references to the target audience or readership\"\n",
      "Model response: 0, 0, 0, 0, 0, 0, 0, 45.17, 45.17, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "Parsed response: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 45.17, 45.17, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Model response: 0, 0, 0, 0, 0, 0, 0, 7.62, 0, 0, 0, 0, 0, 0, 0, 45.17, 0\n",
      "Parsed response: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.62, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 45.17, 0.0]\n",
      "Model response: 0, 0, 0, 0, 0, 0, 0, 0, 15.77, 0, 0, 0, 0, 0, 0, 33.68, 0\n",
      "Parsed response: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 15.77, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 33.68, 0.0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 17.596666666666668, 20.313333333333333, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 26.28333333333333, 0.0]\n",
      "{'hyperparameters': {'basis': 'res-jb',\n",
      "                     'binary_class': False,\n",
      "                     'debug': True,\n",
      "                     'layer': 6,\n",
      "                     'neg_type': 'others',\n",
      "                     'num_completions': 3,\n",
      "                     'num_features': 2,\n",
      "                     'pos_classify_threshold': 0.05,\n",
      "                     'randomize_pos': True,\n",
      "                     'seed': 42,\n",
      "                     'show_max_token': False,\n",
      "                     'show_neg': 0,\n",
      "                     'show_pos': 0,\n",
      "                     'test_neg': 4,\n",
      "                     'test_pos': 4},\n",
      " 'num_features': 2,\n",
      " 'results': [{'description': 'phrases indicating a numerical quantity of '\n",
      "                             'additional items or time',\n",
      "              'feature_index': 2350,\n",
      "              'gpt_predictions': [([0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    16.83867073059082,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0],\n",
      "                                   [0.0,\n",
      "                                    0.0,\n",
      "                                    0.0,\n",
      "                                    0.0,\n",
      "                                    0.0,\n",
      "                                    2.74,\n",
      "                                    16.12666666666667,\n",
      "                                    12.476666666666667,\n",
      "                                    13.726666666666667,\n",
      "                                    0.0,\n",
      "                                    0.0,\n",
      "                                    0.0,\n",
      "                                    0.0,\n",
      "                                    0.0,\n",
      "                                    0.0,\n",
      "                                    0.0,\n",
      "                                    0.0]),\n",
      "                                  ([0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    8.929347038269043,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0],\n",
      "                                   [0.0,\n",
      "                                    0.0,\n",
      "                                    0.0,\n",
      "                                    0.0,\n",
      "                                    0.0,\n",
      "                                    0.0,\n",
      "                                    0.0,\n",
      "                                    0.0,\n",
      "                                    0.0,\n",
      "                                    27.680000000000003,\n",
      "                                    27.680000000000003,\n",
      "                                    41.52,\n",
      "                                    13.840000000000002,\n",
      "                                    0.0,\n",
      "                                    0.0,\n",
      "                                    0.0,\n",
      "                                    0.0]),\n",
      "                                  ([0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    8.909917831420898,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0],\n",
      "                                   [0.0,\n",
      "                                    0.0,\n",
      "                                    0.0,\n",
      "                                    0.0,\n",
      "                                    0.0,\n",
      "                                    0.0,\n",
      "                                    0.0,\n",
      "                                    0.0,\n",
      "                                    0.0,\n",
      "                                    13.840000000000002,\n",
      "                                    0.0,\n",
      "                                    0.0,\n",
      "                                    13.840000000000002,\n",
      "                                    13.840000000000002,\n",
      "                                    0.0,\n",
      "                                    0.0,\n",
      "                                    0.0]),\n",
      "                                  ([0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    34.22396469116211,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0],\n",
      "                                   [0.0,\n",
      "                                    0.0,\n",
      "                                    0.0,\n",
      "                                    0.0,\n",
      "                                    0.0,\n",
      "                                    0.0,\n",
      "                                    2.103333333333333,\n",
      "                                    33.440000000000005,\n",
      "                                    27.680000000000003,\n",
      "                                    41.52,\n",
      "                                    0.0,\n",
      "                                    0.0,\n",
      "                                    0.0,\n",
      "                                    0.0,\n",
      "                                    27.680000000000003,\n",
      "                                    41.52,\n",
      "                                    0.0]),\n",
      "                                  ([0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0],\n",
      "                                   [0.0,\n",
      "                                    0.0,\n",
      "                                    0.0,\n",
      "                                    0.0,\n",
      "                                    0.0,\n",
      "                                    0.0,\n",
      "                                    0.0,\n",
      "                                    0.0,\n",
      "                                    0.0,\n",
      "                                    35.13333333333333,\n",
      "                                    0.0,\n",
      "                                    0.0,\n",
      "                                    0.0,\n",
      "                                    0.0,\n",
      "                                    0.0,\n",
      "                                    0.0,\n",
      "                                    0.0]),\n",
      "                                  ([0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0],\n",
      "                                   [0.0,\n",
      "                                    0.0,\n",
      "                                    0.0,\n",
      "                                    0.0,\n",
      "                                    39.083333333333336,\n",
      "                                    0.0,\n",
      "                                    27.680000000000003,\n",
      "                                    0.0,\n",
      "                                    0.0,\n",
      "                                    0.0,\n",
      "                                    0.0,\n",
      "                                    0.0,\n",
      "                                    0.0,\n",
      "                                    41.52,\n",
      "                                    41.52,\n",
      "                                    13.840000000000002,\n",
      "                                    0.0]),\n",
      "                                  ([0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0],\n",
      "                                   [0.0,\n",
      "                                    0.0,\n",
      "                                    0.0,\n",
      "                                    0.0,\n",
      "                                    0.0,\n",
      "                                    0.0,\n",
      "                                    0.0,\n",
      "                                    0.0,\n",
      "                                    0.0,\n",
      "                                    5.41,\n",
      "                                    0.0,\n",
      "                                    0.0,\n",
      "                                    0.0,\n",
      "                                    13.840000000000002,\n",
      "                                    41.52,\n",
      "                                    5.41,\n",
      "                                    0.0]),\n",
      "                                  ([0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0],\n",
      "                                   [0.0,\n",
      "                                    0.0,\n",
      "                                    0.0,\n",
      "                                    0.0,\n",
      "                                    0.0,\n",
      "                                    0.0,\n",
      "                                    0.0,\n",
      "                                    0.0,\n",
      "                                    0.0,\n",
      "                                    0.0,\n",
      "                                    0.0,\n",
      "                                    0.0,\n",
      "                                    0.0,\n",
      "                                    0.0,\n",
      "                                    0.0,\n",
      "                                    0.0,\n",
      "                                    0.0])],\n",
      "              'highest_activation': 41.52030563354492,\n",
      "              'show_sentences': [],\n",
      "              'test_sentences': [{'max_token': ' more',\n",
      "                                  'max_value': 16.83867073059082,\n",
      "                                  'max_value_token_index': 8,\n",
      "                                  'sentence_string': ' president in prison for '\n",
      "                                                     'up to 30 days more.ĊĊThe '\n",
      "                                                     \"former strongman's\",\n",
      "                                  'tokens': [' president',\n",
      "                                             ' in',\n",
      "                                             ' prison',\n",
      "                                             ' for',\n",
      "                                             ' up',\n",
      "                                             ' to',\n",
      "                                             ' 30',\n",
      "                                             ' days',\n",
      "                                             ' more',\n",
      "                                             '.',\n",
      "                                             'Ċ',\n",
      "                                             'Ċ',\n",
      "                                             'The',\n",
      "                                             ' former',\n",
      "                                             ' strong',\n",
      "                                             'man',\n",
      "                                             \"'s\"],\n",
      "                                  'values': [0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             16.83867073059082,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0]},\n",
      "                                 {'max_token': ' more',\n",
      "                                  'max_value': 8.929347038269043,\n",
      "                                  'max_value_token_index': 8,\n",
      "                                  'sentence_string': ' be, because I am only '\n",
      "                                                     'one of more than fifteen '\n",
      "                                                     'thousand people at Get '\n",
      "                                                     'Motivated',\n",
      "                                  'tokens': [' be',\n",
      "                                             ',',\n",
      "                                             ' because',\n",
      "                                             ' I',\n",
      "                                             ' am',\n",
      "                                             ' only',\n",
      "                                             ' one',\n",
      "                                             ' of',\n",
      "                                             ' more',\n",
      "                                             ' than',\n",
      "                                             ' fifteen',\n",
      "                                             ' thousand',\n",
      "                                             ' people',\n",
      "                                             ' at',\n",
      "                                             ' Get',\n",
      "                                             ' Mot',\n",
      "                                             'ivated'],\n",
      "                                  'values': [0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             8.929347038269043,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0]},\n",
      "                                 {'max_token': ' more',\n",
      "                                  'max_value': 8.909917831420898,\n",
      "                                  'max_value_token_index': 8,\n",
      "                                  'sentence_string': ' any weird noises, and '\n",
      "                                                     'wait for someone more '\n",
      "                                                     'important than you to '\n",
      "                                                     'die.ĊĊ',\n",
      "                                  'tokens': [' any',\n",
      "                                             ' weird',\n",
      "                                             ' noises',\n",
      "                                             ',',\n",
      "                                             ' and',\n",
      "                                             ' wait',\n",
      "                                             ' for',\n",
      "                                             ' someone',\n",
      "                                             ' more',\n",
      "                                             ' important',\n",
      "                                             ' than',\n",
      "                                             ' you',\n",
      "                                             ' to',\n",
      "                                             ' die',\n",
      "                                             '.',\n",
      "                                             'Ċ',\n",
      "                                             'Ċ'],\n",
      "                                  'values': [0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             8.909917831420898,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0]},\n",
      "                                 {'max_token': ' more',\n",
      "                                  'max_value': 34.22396469116211,\n",
      "                                  'max_value_token_index': 8,\n",
      "                                  'sentence_string': \"oevsky's parents \"\n",
      "                                                     'subsequently had six '\n",
      "                                                     'more children: Varvara '\n",
      "                                                     '(1822',\n",
      "                                  'tokens': ['o',\n",
      "                                             'ev',\n",
      "                                             'sky',\n",
      "                                             \"'s\",\n",
      "                                             ' parents',\n",
      "                                             ' subsequently',\n",
      "                                             ' had',\n",
      "                                             ' six',\n",
      "                                             ' more',\n",
      "                                             ' children',\n",
      "                                             ':',\n",
      "                                             ' Var',\n",
      "                                             'v',\n",
      "                                             'ara',\n",
      "                                             ' (',\n",
      "                                             '18',\n",
      "                                             '22'],\n",
      "                                  'values': [0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             34.22396469116211,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0]},\n",
      "                                 {'max_value': 0,\n",
      "                                  'sentence_string': ' a.m. The controller '\n",
      "                                                     'gets off work at 3 p.m. '\n",
      "                                                     'after the',\n",
      "                                  'tokens': [' a',\n",
      "                                             '.',\n",
      "                                             'm',\n",
      "                                             '.',\n",
      "                                             ' The',\n",
      "                                             ' controller',\n",
      "                                             ' gets',\n",
      "                                             ' off',\n",
      "                                             ' work',\n",
      "                                             ' at',\n",
      "                                             ' 3',\n",
      "                                             ' p',\n",
      "                                             '.',\n",
      "                                             'm',\n",
      "                                             '.',\n",
      "                                             ' after',\n",
      "                                             ' the'],\n",
      "                                  'values': [0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0]},\n",
      "                                 {'max_value': 0,\n",
      "                                  'sentence_string': 'PL has increased the '\n",
      "                                                     'number of employees in '\n",
      "                                                     'its legal and risk '\n",
      "                                                     'departments by 41% since',\n",
      "                                  'tokens': ['PL',\n",
      "                                             ' has',\n",
      "                                             ' increased',\n",
      "                                             ' the',\n",
      "                                             ' number',\n",
      "                                             ' of',\n",
      "                                             ' employees',\n",
      "                                             ' in',\n",
      "                                             ' its',\n",
      "                                             ' legal',\n",
      "                                             ' and',\n",
      "                                             ' risk',\n",
      "                                             ' departments',\n",
      "                                             ' by',\n",
      "                                             ' 41',\n",
      "                                             '%',\n",
      "                                             ' since'],\n",
      "                                  'values': [0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0]},\n",
      "                                 {'max_value': 0,\n",
      "                                  'sentence_string': ' Germany Spring, '\n",
      "                                                     'Planetkey Dynamics have '\n",
      "                                                     'announced their first '\n",
      "                                                     'roster change since '\n",
      "                                                     'bringing in four new',\n",
      "                                  'tokens': [' Germany',\n",
      "                                             ' Spring',\n",
      "                                             ',',\n",
      "                                             ' Planet',\n",
      "                                             'key',\n",
      "                                             ' Dynamics',\n",
      "                                             ' have',\n",
      "                                             ' announced',\n",
      "                                             ' their',\n",
      "                                             ' first',\n",
      "                                             ' roster',\n",
      "                                             ' change',\n",
      "                                             ' since',\n",
      "                                             ' bringing',\n",
      "                                             ' in',\n",
      "                                             ' four',\n",
      "                                             ' new'],\n",
      "                                  'values': [0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0]},\n",
      "                                 {'max_value': 0,\n",
      "                                  'sentence_string': 'etted against the '\n",
      "                                                     'evening sky. The steel '\n",
      "                                                     'giants begin moving '\n",
      "                                                     'almost inaudibly,',\n",
      "                                  'tokens': ['et',\n",
      "                                             'ted',\n",
      "                                             ' against',\n",
      "                                             ' the',\n",
      "                                             ' evening',\n",
      "                                             ' sky',\n",
      "                                             '.',\n",
      "                                             ' The',\n",
      "                                             ' steel',\n",
      "                                             ' giants',\n",
      "                                             ' begin',\n",
      "                                             ' moving',\n",
      "                                             ' almost',\n",
      "                                             ' in',\n",
      "                                             'aud',\n",
      "                                             'ibly',\n",
      "                                             ','],\n",
      "                                  'values': [0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0]}]},\n",
      "             {'description': 'references to the target audience or readership',\n",
      "              'feature_index': 23251,\n",
      "              'gpt_predictions': [([0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    36.86307525634766,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0],\n",
      "                                   [0.0,\n",
      "                                    0.0,\n",
      "                                    0.0,\n",
      "                                    0.0,\n",
      "                                    0.0,\n",
      "                                    0.0,\n",
      "                                    0.0,\n",
      "                                    38.86333333333334,\n",
      "                                    44.39666666666667,\n",
      "                                    0.0,\n",
      "                                    0.0,\n",
      "                                    15.056666666666667,\n",
      "                                    0.0,\n",
      "                                    0.0,\n",
      "                                    15.056666666666667,\n",
      "                                    0.0,\n",
      "                                    0.0]),\n",
      "                                  ([0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    5.005291938781738,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0],\n",
      "                                   [0.0,\n",
      "                                    0.0,\n",
      "                                    0.0,\n",
      "                                    0.0,\n",
      "                                    0.0,\n",
      "                                    0.0,\n",
      "                                    0.0,\n",
      "                                    0.0,\n",
      "                                    0.0,\n",
      "                                    0.0,\n",
      "                                    0.0,\n",
      "                                    0.0,\n",
      "                                    11.706666666666665,\n",
      "                                    13.423333333333334,\n",
      "                                    0.0,\n",
      "                                    15.056666666666667,\n",
      "                                    0.0]),\n",
      "                                  ([0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    17.6229248046875,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0],\n",
      "                                   [0.0,\n",
      "                                    0.0,\n",
      "                                    0.0,\n",
      "                                    0.0,\n",
      "                                    0.0,\n",
      "                                    0.0,\n",
      "                                    0.0,\n",
      "                                    31.156666666666666,\n",
      "                                    45.169999999999995,\n",
      "                                    0.0,\n",
      "                                    0.0,\n",
      "                                    0.0,\n",
      "                                    0.0,\n",
      "                                    0.0,\n",
      "                                    0.0,\n",
      "                                    0.0,\n",
      "                                    0.0]),\n",
      "                                  ([0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    20.7180233001709,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0],\n",
      "                                   [0.0,\n",
      "                                    0.0,\n",
      "                                    0.0,\n",
      "                                    0.0,\n",
      "                                    0.0,\n",
      "                                    0.0,\n",
      "                                    0.0,\n",
      "                                    0.0,\n",
      "                                    29.133333333333336,\n",
      "                                    7.536666666666666,\n",
      "                                    0.0,\n",
      "                                    0.0,\n",
      "                                    0.0,\n",
      "                                    0.0,\n",
      "                                    0.0,\n",
      "                                    0.0,\n",
      "                                    0.0]),\n",
      "                                  ([0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0],\n",
      "                                   [0.0,\n",
      "                                    0.0,\n",
      "                                    0.0,\n",
      "                                    3.7466666666666666,\n",
      "                                    0.0,\n",
      "                                    0.0,\n",
      "                                    0.0,\n",
      "                                    0.0,\n",
      "                                    0.0,\n",
      "                                    0.0,\n",
      "                                    0.0,\n",
      "                                    0.0,\n",
      "                                    18.973333333333333,\n",
      "                                    15.056666666666667,\n",
      "                                    0.0,\n",
      "                                    0.0,\n",
      "                                    0.0]),\n",
      "                                  ([0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0],\n",
      "                                   [0.0,\n",
      "                                    0.0,\n",
      "                                    0.0,\n",
      "                                    0.0,\n",
      "                                    0.0,\n",
      "                                    0.0,\n",
      "                                    32.32,\n",
      "                                    0.0,\n",
      "                                    0.0,\n",
      "                                    0.0,\n",
      "                                    0.0,\n",
      "                                    0.0,\n",
      "                                    15.056666666666667,\n",
      "                                    0.0,\n",
      "                                    0.0,\n",
      "                                    0.0,\n",
      "                                    0.0]),\n",
      "                                  ([0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0],\n",
      "                                   [0.0,\n",
      "                                    0.0,\n",
      "                                    0.0,\n",
      "                                    0.0,\n",
      "                                    0.0,\n",
      "                                    0.0,\n",
      "                                    0.0,\n",
      "                                    26.25666666666667,\n",
      "                                    0.0,\n",
      "                                    0.0,\n",
      "                                    0.0,\n",
      "                                    0.0,\n",
      "                                    7.723333333333334,\n",
      "                                    14.39,\n",
      "                                    0.0,\n",
      "                                    0.0,\n",
      "                                    0.0]),\n",
      "                                  ([0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0,\n",
      "                                    0],\n",
      "                                   [0.0,\n",
      "                                    0.0,\n",
      "                                    0.0,\n",
      "                                    0.0,\n",
      "                                    0.0,\n",
      "                                    0.0,\n",
      "                                    0.0,\n",
      "                                    17.596666666666668,\n",
      "                                    20.313333333333333,\n",
      "                                    0.0,\n",
      "                                    0.0,\n",
      "                                    0.0,\n",
      "                                    0.0,\n",
      "                                    0.0,\n",
      "                                    0.0,\n",
      "                                    26.28333333333333,\n",
      "                                    0.0])],\n",
      "              'highest_activation': 45.1700439453125,\n",
      "              'show_sentences': [],\n",
      "              'test_sentences': [{'max_token': ' audience',\n",
      "                                  'max_value': 36.86307525634766,\n",
      "                                  'max_value_token_index': 8,\n",
      "                                  'sentence_string': ' Combat for the first '\n",
      "                                                     'time to a live '\n",
      "                                                     'audience.ĊĊThe two weeks '\n",
      "                                                     'before the',\n",
      "                                  'tokens': [' Combat',\n",
      "                                             ' for',\n",
      "                                             ' the',\n",
      "                                             ' first',\n",
      "                                             ' time',\n",
      "                                             ' to',\n",
      "                                             ' a',\n",
      "                                             ' live',\n",
      "                                             ' audience',\n",
      "                                             '.',\n",
      "                                             'Ċ',\n",
      "                                             'Ċ',\n",
      "                                             'The',\n",
      "                                             ' two',\n",
      "                                             ' weeks',\n",
      "                                             ' before',\n",
      "                                             ' the'],\n",
      "                                  'values': [0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             36.86307525634766,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0]},\n",
      "                                 {'max_token': ' constituency',\n",
      "                                  'max_value': 5.005291938781738,\n",
      "                                  'max_value_token_index': 8,\n",
      "                                  'sentence_string': ' accommodation on a site '\n",
      "                                                     'in her south Dublin '\n",
      "                                                     'constituency would be \"a '\n",
      "                                                     'waste of valuable '\n",
      "                                                     'resources',\n",
      "                                  'tokens': [' accommodation',\n",
      "                                             ' on',\n",
      "                                             ' a',\n",
      "                                             ' site',\n",
      "                                             ' in',\n",
      "                                             ' her',\n",
      "                                             ' south',\n",
      "                                             ' Dublin',\n",
      "                                             ' constituency',\n",
      "                                             ' would',\n",
      "                                             ' be',\n",
      "                                             ' \"',\n",
      "                                             'a',\n",
      "                                             ' waste',\n",
      "                                             ' of',\n",
      "                                             ' valuable',\n",
      "                                             ' resources'],\n",
      "                                  'values': [0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             5.005291938781738,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0]},\n",
      "                                 {'max_token': ' audiences',\n",
      "                                  'max_value': 17.6229248046875,\n",
      "                                  'max_value_token_index': 8,\n",
      "                                  'sentence_string': ' to Rs 600 cr.The film '\n",
      "                                                     'fascinated audiences '\n",
      "                                                     'because of its visual '\n",
      "                                                     'effects. The fact',\n",
      "                                  'tokens': [' to',\n",
      "                                             ' Rs',\n",
      "                                             ' 600',\n",
      "                                             ' cr',\n",
      "                                             '.',\n",
      "                                             'The',\n",
      "                                             ' film',\n",
      "                                             ' fascinated',\n",
      "                                             ' audiences',\n",
      "                                             ' because',\n",
      "                                             ' of',\n",
      "                                             ' its',\n",
      "                                             ' visual',\n",
      "                                             ' effects',\n",
      "                                             '.',\n",
      "                                             ' The',\n",
      "                                             ' fact'],\n",
      "                                  'values': [0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             17.6229248046875,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0]},\n",
      "                                 {'max_token': ' audiences',\n",
      "                                  'max_value': 20.7180233001709,\n",
      "                                  'max_value_token_index': 8,\n",
      "                                  'sentence_string': ' but she is perhaps best '\n",
      "                                                     'known to Western '\n",
      "                                                     'audiences for her '\n",
      "                                                     'feature-film roles in '\n",
      "                                                     '1997',\n",
      "                                  'tokens': [' but',\n",
      "                                             ' she',\n",
      "                                             ' is',\n",
      "                                             ' perhaps',\n",
      "                                             ' best',\n",
      "                                             ' known',\n",
      "                                             ' to',\n",
      "                                             ' Western',\n",
      "                                             ' audiences',\n",
      "                                             ' for',\n",
      "                                             ' her',\n",
      "                                             ' feature',\n",
      "                                             '-',\n",
      "                                             'film',\n",
      "                                             ' roles',\n",
      "                                             ' in',\n",
      "                                             ' 1997'],\n",
      "                                  'values': [0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             20.7180233001709,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0]},\n",
      "                                 {'max_value': 0,\n",
      "                                  'sentence_string': 't know. We just kind of '\n",
      "                                                     'hang out, I guess we '\n",
      "                                                     'havenâĢĻt',\n",
      "                                  'tokens': ['t',\n",
      "                                             ' know',\n",
      "                                             '.',\n",
      "                                             ' We',\n",
      "                                             ' just',\n",
      "                                             ' kind',\n",
      "                                             ' of',\n",
      "                                             ' hang',\n",
      "                                             ' out',\n",
      "                                             ',',\n",
      "                                             ' I',\n",
      "                                             ' guess',\n",
      "                                             ' we',\n",
      "                                             ' haven',\n",
      "                                             'âĢ',\n",
      "                                             'Ļ',\n",
      "                                             't'],\n",
      "                                  'values': [0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0]},\n",
      "                                 {'max_value': 0,\n",
      "                                  'sentence_string': ' time, âĢľWhat do you '\n",
      "                                                     'actually eat?âĢĿ The '\n",
      "                                                     'post, aptly titled',\n",
      "                                  'tokens': [' time',\n",
      "                                             ',',\n",
      "                                             ' âĢ',\n",
      "                                             'ľ',\n",
      "                                             'What',\n",
      "                                             ' do',\n",
      "                                             ' you',\n",
      "                                             ' actually',\n",
      "                                             ' eat',\n",
      "                                             '?',\n",
      "                                             'âĢ',\n",
      "                                             'Ŀ',\n",
      "                                             ' The',\n",
      "                                             ' post',\n",
      "                                             ',',\n",
      "                                             ' aptly',\n",
      "                                             ' titled'],\n",
      "                                  'values': [0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0]},\n",
      "                                 {'max_value': 0,\n",
      "                                  'sentence_string': ' overnight into Tuesday, '\n",
      "                                                     'two fatally. The '\n",
      "                                                     'newspaper says those '\n",
      "                                                     'shootings bring the '\n",
      "                                                     'total number shot',\n",
      "                                  'tokens': [' overnight',\n",
      "                                             ' into',\n",
      "                                             ' Tuesday',\n",
      "                                             ',',\n",
      "                                             ' two',\n",
      "                                             ' fatally',\n",
      "                                             '.',\n",
      "                                             ' The',\n",
      "                                             ' newspaper',\n",
      "                                             ' says',\n",
      "                                             ' those',\n",
      "                                             ' shootings',\n",
      "                                             ' bring',\n",
      "                                             ' the',\n",
      "                                             ' total',\n",
      "                                             ' number',\n",
      "                                             ' shot'],\n",
      "                                  'values': [0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0]},\n",
      "                                 {'max_value': 0,\n",
      "                                  'sentence_string': ' through that hole in '\n",
      "                                                     'the hull? The one my '\n",
      "                                                     'security chief was just '\n",
      "                                                     'sucked out of',\n",
      "                                  'tokens': [' through',\n",
      "                                             ' that',\n",
      "                                             ' hole',\n",
      "                                             ' in',\n",
      "                                             ' the',\n",
      "                                             ' hull',\n",
      "                                             '?',\n",
      "                                             ' The',\n",
      "                                             ' one',\n",
      "                                             ' my',\n",
      "                                             ' security',\n",
      "                                             ' chief',\n",
      "                                             ' was',\n",
      "                                             ' just',\n",
      "                                             ' sucked',\n",
      "                                             ' out',\n",
      "                                             ' of'],\n",
      "                                  'values': [0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0,\n",
      "                                             0]}]}],\n",
      " 'timestamp': 1716587721.9048352}\n"
     ]
    }
   ],
   "source": [
    "results = run_experiments(\n",
    "    num_features=2, \n",
    "    layer=6,\n",
    "    basis='res-jb',\n",
    "    test_pos=4, # Experiment with\n",
    "    test_neg=4, # Experiment with\n",
    "    show_pos=0, # Experiment with\n",
    "    show_neg=0, # Experiment with\n",
    "    neg_type='others', # Experiment with\n",
    "    binary_class=False, # Experiment with\n",
    "    all_tokens=True,\n",
    "    show_max_token=False, # Experiment with\n",
    "    num_completions=3, # Experiment with\n",
    "    debug=True, \n",
    "    randomize_pos=True, \n",
    "    save_location='test',\n",
    "    feature_ids=indices\n",
    ")\n",
    "\n",
    "# # the run_experiments function automatically saves results to results/exp_{timestamp}.json\n",
    "pprint.pprint(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{\n",
      "modelId\n",
      "layer\n",
      "index\n",
      "maxActApprox\n",
      "frac_nonzero\n",
      "freq_hist_data_bar_heights []\n",
      "    .\n",
      "    .\n",
      "    .\n",
      "freq_hist_data_bar_values []\n",
      "    .\n",
      "    .\n",
      "    .\n",
      "logits_hist_data_bar_heights []\n",
      "    .\n",
      "    .\n",
      "    .\n",
      "logits_hist_data_bar_values []\n",
      "    .\n",
      "    .\n",
      "    .\n",
      "neg_str []\n",
      "    .\n",
      "    .\n",
      "    .\n",
      "neg_values []\n",
      "    .\n",
      "    .\n",
      "    .\n",
      "pos_str []\n",
      "    .\n",
      "    .\n",
      "    .\n",
      "pos_values []\n",
      "    .\n",
      "    .\n",
      "    .\n",
      "activations []\n",
      "        {\n",
      "        id\n",
      "        tokens []\n",
      "            .\n",
      "            .\n",
      "            .\n",
      "        maxValue\n",
      "        minValue\n",
      "        values []\n",
      "            .\n",
      "            .\n",
      "            .\n",
      "        maxValueTokenIndex\n",
      "        lossValues []\n",
      "            .\n",
      "            .\n",
      "            .\n",
      "        }\n",
      "\n",
      "    .\n",
      "    .\n",
      "    .\n",
      "explanations []\n",
      "        {\n",
      "        id\n",
      "        description\n",
      "        umap_cluster\n",
      "        umap_log_feature_sparsity\n",
      "        umap_x\n",
      "        umap_y\n",
      "        scoreV1\n",
      "        scoreV2\n",
      "        }\n",
      "\n",
      "    .\n",
      "    .\n",
      "    .\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Read the JSON file\n",
    "with open('6-res-jb_subset_100/428.json', 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Print the JSON structure\n",
    "print_json_tree(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do analysis on loaded json_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_data_binary = load_json_results('results/binary_test/exp_binary_others.json')\n",
    "json_data_continuous = load_json_results('results/binary_test/exp_continuous_others.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_preds = [json_data_binary['results'][i]['gpt_predictions'] for i in range(len(json_data_binary['results']))]\n",
    "continuous_preds = [json_data_continuous['results'][i]['gpt_predictions'] for i in range(len(json_data_continuous['results']))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "accuracy = get_binary_accuracy(binary_preds, plot_cdf=True, plot_distribution=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.4, 0.0, 0.8, 'dates or time-related information')\n",
      "(0.4, 0.6, 0.2, 'words signaling conflicting or contrasting information')\n",
      "(0.4, 0.0, 0.8, 'phrases related to legal issues and law enforcement')\n",
      "(0.4, 0.0, 0.8, 'phrases that are commonly used in research or formal reports')\n",
      "(0.5,\n",
      " 0.0,\n",
      " 1.0,\n",
      " 'references to locations or events related to the state of Florida')\n",
      "(0.5, 0.0, 1.0, 'metaphorical expressions related to success and achievement')\n",
      "(0.5, 0.0, 1.0, 'numbers and financial terms')\n",
      "(0.5, 0.2, 0.8, 'disparities between genders or races in various aspects')\n",
      "(0.5, 0.0, 1.0, 'words related to elements from the periodic table')\n",
      "(0.5, 0.0, 1.0, 'names of specific computer software or platforms')\n",
      "(0.5, 0.0, 1.0, 'mentions of specific locations, with a focus on New York City')\n",
      "(0.5,\n",
      " 0.2,\n",
      " 0.8,\n",
      " 'instances where something is considered problematic or controversial')\n",
      "(0.5, 0.0, 1.0, 'references to email sharing')\n",
      "(0.5,\n",
      " 0.0,\n",
      " 1.0,\n",
      " 'attributes related to products such as being inexpensive, lasting, '\n",
      " 'versatile, creamy, light, and resistant')\n",
      "(0.5, 0.2, 0.8, 'mentions of business-related terms and concepts')\n",
      "(0.5, 0.0, 1.0, 'names of cities and places')\n",
      "(0.5, 0.0, 1.0, 'phrases related to statistical margins of error')\n",
      "(0.5, 0.0, 1.0, 'numerical information or technological terms')\n",
      "(0.5, 0.0, 1.0, 'phrases related to teaching, training, or mentoring')\n",
      "(0.5,\n",
      " 0.0,\n",
      " 1.0,\n",
      " 'terms related to various topics such as mutations, users, medals, school, '\n",
      " 'submarines, players, trees, sellers, referees, test flights, exceptions, '\n",
      " 'songs, wins, fossils, arguments, hostages, students, distributions, goals, '\n",
      " 'monsters, registers, candidates')\n",
      "(0.5, 0.0, 1.0, 'colors')\n",
      "(0.5, 0.2, 0.8, 'dates or months mentioned within texts')\n",
      "(0.5,\n",
      " 0.6,\n",
      " 0.4,\n",
      " 'specific phrases or proper nouns within longer strings of text')\n",
      "(0.5,\n",
      " 0.0,\n",
      " 1.0,\n",
      " 'references related to data storage & technology, particularly mentioning SD '\n",
      " 'cards and software development kits (SDKs)')\n",
      "(0.5, 0.0, 1.0, 'phrases related to education and training programs')\n",
      "(0.5, 0.2, 0.8, 'instances of rules and regulations being violated')\n",
      "(0.5, 0.4, 0.6, 'verbs related to actions, decisions, and intentions')\n",
      "(0.6, 0.2, 1.0, 'timestamps or dates in a specific format')\n",
      "(0.6, 0.2, 1.0, 'scientific or investigative terms and concepts')\n",
      "(0.6, 0.4, 0.8, 'Proper nouns related to politics, names, and affiliations')\n",
      "(0.6, 0.2, 1.0, 'questions posed in a somewhat dramatic or urgent manner')\n",
      "(0.6, 0.4, 0.8, 'periods at the end of sentences')\n",
      "(0.6, 0.2, 1.0, 'mentions of statistical information and survey results')\n",
      "(0.6,\n",
      " 0.2,\n",
      " 1.0,\n",
      " 'business-related terms, especially those related to financial markets and '\n",
      " 'corporate activities')\n",
      "(0.6, 0.2, 1.0, 'proper nouns related to fantasy worlds and characters')\n",
      "(0.6,\n",
      " 0.2,\n",
      " 1.0,\n",
      " 'phrases related to accepting terms and conditions for receiving updates')\n",
      "(0.6, 0.2, 1.0, 'reference to notable people or famous figures')\n",
      "(0.6, 0.6, 0.6, 'points or main ideas within the text')\n",
      "(0.6,\n",
      " 0.8,\n",
      " 0.4,\n",
      " 'phrases that seem to be randomly generated or lack coherent meaning')\n",
      "(0.6, 0.2, 1.0, 'words related to Serbian culture or history')\n",
      "(0.6,\n",
      " 0.2,\n",
      " 1.0,\n",
      " 'phrases indicating comparison or evaluation, focusing on the outcome or '\n",
      " 'result')\n",
      "(0.6, 0.2, 1.0, 'numerical values related to quantities or limits')\n",
      "(0.6, 1.0, 0.2, 'phrases related to news or events')\n",
      "(0.6, 0.2, 1.0, 'words related to locations or places')\n",
      "(0.6, 0.6, 0.6, 'verbs related to influencing or persuading others')\n",
      "(0.6, 0.2, 1.0, 'contact information in documents')\n",
      "(0.6, 0.2, 1.0, 'phrases involving step-by-step instructions')\n",
      "(0.6, 0.2, 1.0, 'words related to work, job satisfaction, and daily routines')\n",
      "(0.6, 0.2, 1.0, 'references to the brand \"Nestlé.\"')\n",
      "(0.7, 0.4, 1.0, 'references to cartoon characters')\n",
      "(0.7,\n",
      " 0.4,\n",
      " 1.0,\n",
      " 'technical terms related to programming or scripting languages and '\n",
      " 'development tools')\n",
      "(0.7, 0.4, 1.0, 'statistics and data related terms')\n",
      "(0.7,\n",
      " 0.4,\n",
      " 1.0,\n",
      " 'words related to technology and companies, as well as names of specific '\n",
      " 'technological devices and software')\n",
      "(0.7, 0.4, 1.0, 'mentions of the news network \"Al Jazeera\"')\n",
      "(0.7, 0.6, 0.8, 'terms related to names and specific locations')\n",
      "(0.7,\n",
      " 0.6,\n",
      " 0.8,\n",
      " 'words related to responses, reactions, and attitudes towards events or '\n",
      " 'announcements')\n",
      "(0.7, 0.4, 1.0, 'phrases related to inclusivity and equality for all')\n",
      "(0.7, 0.4, 1.0, 'phrases related to organizations or official entities')\n",
      "(0.7, 0.6, 0.8, 'terms related to social issues and political concepts')\n",
      "(0.7, 0.8, 0.6, 'words related to problems or challenges')\n",
      "(0.7, 0.6, 0.8, 'words related to negative actions or emotions')\n",
      "(0.7, 0.4, 1.0, 'names of individuals')\n",
      "(0.8, 0.6, 1.0, 'references to locations in the United States')\n",
      "(0.8, 0.6, 1.0, 'terms related to physical structures')\n",
      "(0.8,\n",
      " 0.8,\n",
      " 0.8,\n",
      " 'references to actions that users can perform or services they can access')\n",
      "(0.8, 0.6, 1.0, 'references to a large quantity or group of people')\n",
      "(0.8, 0.6, 1.0, 'mentions of the Syrian President, Bashar al-Assad')\n",
      "(0.8, 0.6, 1.0, 'words related to style or stylization')\n",
      "(0.8, 0.6, 1.0, 'phrases related to the concept of location or direction')\n",
      "(0.8,\n",
      " 0.6,\n",
      " 1.0,\n",
      " 'phrases related to incidents or events involving violence or law enforcement')\n",
      "(0.8, 0.6, 1.0, 'adjectives describing the quality of a job or task being done')\n",
      "(0.8, 0.6, 1.0, 'mentions of \"Disney\" related content')\n",
      "(0.8,\n",
      " 0.8,\n",
      " 0.8,\n",
      " 'phrases indicating uncertainty or anticipation of future events')\n",
      "(0.8, 0.6, 1.0, 'specific numerical patterns')\n",
      "(0.8,\n",
      " 0.6,\n",
      " 1.0,\n",
      " 'mentions instructing or receiving something in a document, potentially '\n",
      " 'related to terms of use or agreements')\n",
      "(0.8, 0.6, 1.0, 'references to political entities or government positions')\n",
      "(0.8,\n",
      " 0.6,\n",
      " 1.0,\n",
      " \"phrases or descriptions related to someone's character or impact\")\n",
      "(0.8,\n",
      " 0.6,\n",
      " 1.0,\n",
      " \"phrases related to social interactions involving people's behaviors and \"\n",
      " 'relationships')\n",
      "(0.8, 0.6, 1.0, 'time-related terms')\n",
      "(0.9,\n",
      " 0.8,\n",
      " 1.0,\n",
      " 'mentions of the name \"Christian\" along with various contexts like sports, '\n",
      " 'events, and other individuals')\n",
      "(0.9, 1.0, 0.8, 'references to various conspiracy theories')\n",
      "(0.9,\n",
      " 0.8,\n",
      " 1.0,\n",
      " 'language related to appreciation and support, especially in the context of '\n",
      " 'online participation and activism')\n",
      "(0.9, 1.0, 0.8, 'words related to voting or expressing a choice')\n",
      "(0.9, 0.8, 1.0, 'the name \"Ali\" in the text')\n",
      "(0.9,\n",
      " 0.8,\n",
      " 1.0,\n",
      " 'proper names starting with the letter \"B\" associated with various events, '\n",
      " 'individuals, or places')\n",
      "(0.9, 0.8, 1.0, 'political party names and related terms')\n",
      "(0.9,\n",
      " 1.0,\n",
      " 0.8,\n",
      " 'mentions of specific historical figures, particularly related to political '\n",
      " 'contexts')\n",
      "(0.9, 0.8, 1.0, 'non-profit organizations or initiatives')\n",
      "(0.9, 0.8, 1.0, 'historical events or timelines')\n",
      "(0.9,\n",
      " 0.8,\n",
      " 1.0,\n",
      " 'phrases related to genetics and DNA, particularly focusing on the word '\n",
      " '\"gene.\"')\n",
      "(0.9, 0.8, 1.0, 'image and HTML code related phrases')\n",
      "(0.9, 0.8, 1.0, 'references to the term \"Ho\"')\n",
      "(1.0, 1.0, 1.0, 'various URLs and related alphanumeric patterns')\n",
      "(1.0, 1.0, 1.0, 'mentions of college-related terms')\n",
      "(1.0,\n",
      " 1.0,\n",
      " 1.0,\n",
      " 'mentions of people in different professional roles or positions, potentially '\n",
      " 'in quotes or attributed statements')\n",
      "(1.0, 1.0, 1.0, 'websites or URLs')\n",
      "(1.0, 1.0, 1.0, 'phrases indicating accessibility to the public')\n",
      "(1.0, 1.0, 1.0, 'instances of the word \"before\" followed by an action')\n",
      "(1.0, 1.0, 1.0, 'words related to hosting or being a host')\n",
      "(1.0, 1.0, 1.0, 'the word \"House\" followed by another word or phrase')\n"
     ]
    }
   ],
   "source": [
    "accuracy_descs = get_accuracy_descs(json_data_binary, include_pos_neg=True, display=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt2-small/6/1248-1280.json\n",
      "gpt2-small/6/1088-1120.json\n",
      "gpt2-small/6/1056-1088.json\n",
      "gpt2-small/6/192-224.json\n",
      "gpt2-small/6/1312-1344.json\n",
      "gpt2-small/6/608-640.json\n",
      "gpt2-small/6/2624-2656.json\n",
      "gpt2-small/6/224-256.json\n",
      "gpt2-small/6/2720-2752.json\n",
      "gpt2-small/6/1568-1600.json\n",
      "gpt2-small/6/2240-2272.json\n",
      "gpt2-small/6/960-992.json\n",
      "gpt2-small/6/480-512.json\n",
      "gpt2-small/6/2752-2784.json\n",
      "gpt2-small/6/3008-3040.json\n",
      "gpt2-small/6/128-160.json\n",
      "gpt2-small/6/1504-1536.json\n",
      "gpt2-small/6/2880-2912.json\n",
      "gpt2-small/6/448-480.json\n",
      "gpt2-small/6/2592-2624.json\n",
      "gpt2-small/6/2976-3008.json\n",
      "gpt2-small/6/2816-2848.json\n",
      "gpt2-small/6/2944-2976.json\n",
      "gpt2-small/6/1472-1504.json\n",
      "gpt2-small/6/1824-1856.json\n",
      "gpt2-small/6/1792-1824.json\n",
      "gpt2-small/6/992-1024.json\n",
      "gpt2-small/6/672-704.json\n",
      "gpt2-small/6/1952-1984.json\n",
      "gpt2-small/6/1920-1952.json\n",
      "gpt2-small/6/1184-1216.json\n",
      "gpt2-small/6/352-384.json\n",
      "gpt2-small/6/160-192.json\n",
      "gpt2-small/6/704-736.json\n",
      "gpt2-small/6/2112-2144.json\n",
      "gpt2-small/6/864-896.json\n",
      "gpt2-small/6/928-960.json\n",
      "gpt2-small/6/2048-2080.json\n",
      "gpt2-small/6/32-64.json\n",
      "gpt2-small/6/2336-2368.json\n",
      "gpt2-small/6/64-96.json\n",
      "gpt2-small/6/416-448.json\n",
      "gpt2-small/6/1408-1440.json\n",
      "gpt2-small/6/320-352.json\n",
      "gpt2-small/6/1280-1312.json\n",
      "gpt2-small/6/896-928.json\n",
      "gpt2-small/6/1024-1056.json\n",
      "gpt2-small/6/512-544.json\n",
      "gpt2-small/6/544-576.json\n",
      "gpt2-small/6/2688-2720.json\n",
      "gpt2-small/6/640-672.json\n",
      "gpt2-small/6/2656-2688.json\n",
      "gpt2-small/6/2560-2592.json\n",
      "gpt2-small/6/768-800.json\n",
      "gpt2-small/6/2496-2528.json\n",
      "gpt2-small/6/2464-2496.json\n",
      "gpt2-small/6/1344-1376.json\n",
      "gpt2-small/6/1984-2016.json\n",
      "gpt2-small/6/2528-2560.json\n",
      "gpt2-small/6/1152-1184.json\n",
      "gpt2-small/6/832-864.json\n",
      "gpt2-small/6/1376-1408.json\n",
      "gpt2-small/6/1120-1152.json\n",
      "gpt2-small/6/1216-1248.json\n",
      "gpt2-small/6/1632-1664.json\n",
      "gpt2-small/6/1440-1472.json\n",
      "gpt2-small/6/2176-2208.json\n",
      "gpt2-small/6/2912-2944.json\n",
      "gpt2-small/6/2304-2336.json\n",
      "gpt2-small/6/256-288.json\n",
      "gpt2-small/6/2848-2880.json\n",
      "gpt2-small/6/2400-2432.json\n",
      "gpt2-small/6/736-768.json\n",
      "gpt2-small/6/384-416.json\n",
      "gpt2-small/6/288-320.json\n",
      "gpt2-small/6/1888-1920.json\n",
      "gpt2-small/6/1600-1632.json\n",
      "gpt2-small/6/1856-1888.json\n",
      "gpt2-small/6/0-32.json\n",
      "gpt2-small/6/2272-2304.json\n",
      "gpt2-small/6/2784-2816.json\n",
      "gpt2-small/6/800-832.json\n",
      "gpt2-small/6/1696-1728.json\n",
      "gpt2-small/6/1760-1792.json\n",
      "gpt2-small/6/2080-2112.json\n",
      "gpt2-small/6/2016-2048.json\n",
      "gpt2-small/6/2368-2400.json\n",
      "gpt2-small/6/2208-2240.json\n",
      "gpt2-small/6/2432-2464.json\n",
      "gpt2-small/6/576-608.json\n",
      "gpt2-small/6/2144-2176.json\n",
      "gpt2-small/6/1728-1760.json\n",
      "gpt2-small/6/1664-1696.json\n",
      "gpt2-small/6/96-128.json\n",
      "gpt2-small/6/3040-3072.json\n",
      "gpt2-small/6/1536-1568.json\n",
      "gpt2-small/6-res-jb/14848-15104.json\n",
      "gpt2-small/6-res-jb/15360-15616.json\n",
      "gpt2-small/6-res-jb/10240-10496.json\n",
      "gpt2-small/6-res-jb/10752-11008.json\n",
      "gpt2-small/6-res-jb/9728-9984.json\n",
      "gpt2-small/6-res-jb/22528-22784.json\n",
      "gpt2-small/6-res-jb/14080-14336.json\n",
      "gpt2-small/6-res-jb/3072-3328.json\n",
      "gpt2-small/6-res-jb/17920-18176.json\n",
      "gpt2-small/6-res-jb/16384-16640.json\n",
      "gpt2-small/6-res-jb/4608-4864.json\n",
      "gpt2-small/6-res-jb/6400-6656.json\n",
      "gpt2-small/6-res-jb/19200-19456.json\n",
      "gpt2-small/6-res-jb/20224-20480.json\n",
      "gpt2-small/6-res-jb/6144-6400.json\n",
      "gpt2-small/6-res-jb/4864-5120.json\n",
      "gpt2-small/6-res-jb/23552-23808.json\n",
      "gpt2-small/6-res-jb/5120-5376.json\n",
      "gpt2-small/6-res-jb/24320-24576.json\n",
      "gpt2-small/6-res-jb/7424-7680.json\n",
      "gpt2-small/6-res-jb/23296-23552.json\n",
      "gpt2-small/6-res-jb/23040-23296.json\n",
      "gpt2-small/6-res-jb/3584-3840.json\n",
      "gpt2-small/6-res-jb/19712-19968.json\n",
      "gpt2-small/6-res-jb/20736-20992.json\n",
      "gpt2-small/6-res-jb/13824-14080.json\n",
      "gpt2-small/6-res-jb/8960-9216.json\n",
      "gpt2-small/6-res-jb/1536-1792.json\n",
      "gpt2-small/6-res-jb/12032-12288.json\n",
      "gpt2-small/6-res-jb/5888-6144.json\n",
      "gpt2-small/6-res-jb/8448-8704.json\n",
      "gpt2-small/6-res-jb/2560-2816.json\n",
      "gpt2-small/6-res-jb/1024-1280.json\n",
      "gpt2-small/6-res-jb/12288-12544.json\n",
      "gpt2-small/6-res-jb/1792-2048.json\n",
      "gpt2-small/6-res-jb/15616-15872.json\n",
      "gpt2-small/6-res-jb/7680-7936.json\n",
      "gpt2-small/6-res-jb/1280-1536.json\n",
      "gpt2-small/6-res-jb/4352-4608.json\n",
      "gpt2-small/6-res-jb/5632-5888.json\n",
      "gpt2-small/6-res-jb/19968-20224.json\n",
      "gpt2-small/6-res-jb/2816-3072.json\n",
      "gpt2-small/6-res-jb/22016-22272.json\n",
      "gpt2-small/6-res-jb/17408-17664.json\n",
      "gpt2-small/6-res-jb/20992-21248.json\n",
      "gpt2-small/6-res-jb/14592-14848.json\n",
      "gpt2-small/6-res-jb/9216-9472.json\n",
      "gpt2-small/6-res-jb/13056-13312.json\n",
      "gpt2-small/6-res-jb/17664-17920.json\n",
      "gpt2-small/6-res-jb/8704-8960.json\n",
      "gpt2-small/6-res-jb/7936-8192.json\n",
      "gpt2-small/6-res-jb/21504-21760.json\n",
      "gpt2-small/6-res-jb/768-1024.json\n",
      "gpt2-small/6-res-jb/20480-20736.json\n",
      "gpt2-small/6-res-jb/16128-16384.json\n",
      "gpt2-small/6-res-jb/24064-24320.json\n",
      "gpt2-small/6-res-jb/2048-2304.json\n",
      "gpt2-small/6-res-jb/8192-8448.json\n",
      "gpt2-small/6-res-jb/5376-5632.json\n",
      "gpt2-small/6-res-jb/18432-18688.json\n",
      "gpt2-small/6-res-jb/18176-18432.json\n",
      "gpt2-small/6-res-jb/10496-10752.json\n",
      "gpt2-small/6-res-jb/15872-16128.json\n",
      "gpt2-small/6-res-jb/7168-7424.json\n",
      "gpt2-small/6-res-jb/22272-22528.json\n",
      "gpt2-small/6-res-jb/3840-4096.json\n",
      "gpt2-small/6-res-jb/256-512.json\n",
      "gpt2-small/6-res-jb/16640-16896.json\n",
      "gpt2-small/6-res-jb/22784-23040.json\n",
      "gpt2-small/6-res-jb/18688-18944.json\n",
      "gpt2-small/6-res-jb/512-768.json\n",
      "gpt2-small/6-res-jb/11008-11264.json\n",
      "gpt2-small/6-res-jb/3328-3584.json\n",
      "gpt2-small/6-res-jb/9472-9728.json\n",
      "gpt2-small/6-res-jb/9984-10240.json\n",
      "gpt2-small/6-res-jb/2304-2560.json\n",
      "gpt2-small/6-res-jb/11264-11520.json\n",
      "gpt2-small/6-res-jb/13312-13568.json\n",
      "gpt2-small/6-res-jb/13568-13824.json\n",
      "gpt2-small/6-res-jb/0-256.json\n",
      "gpt2-small/6-res-jb/14336-14592.json\n",
      "gpt2-small/6-res-jb/21248-21504.json\n",
      "gpt2-small/6-res-jb/23808-24064.json\n",
      "gpt2-small/6-res-jb/11520-11776.json\n",
      "gpt2-small/6-res-jb/17152-17408.json\n",
      "gpt2-small/6-res-jb/15104-15360.json\n",
      "gpt2-small/6-res-jb/18944-19200.json\n",
      "gpt2-small/6-res-jb/12800-13056.json\n",
      "gpt2-small/6-res-jb/12544-12800.json\n",
      "gpt2-small/6-res-jb/16896-17152.json\n",
      "gpt2-small/6-res-jb/19456-19712.json\n",
      "gpt2-small/6-res-jb/11776-12032.json\n",
      "gpt2-small/6-res-jb/4096-4352.json\n",
      "gpt2-small/6-res-jb/6912-7168.json\n",
      "gpt2-small/6-res-jb/6656-6912.json\n",
      "gpt2-small/6-res-jb/21760-22016.json\n"
     ]
    }
   ],
   "source": [
    "resave_organized_modeldata(autoencoder_layers = [6],\n",
    "                        autoencoder_bases = [\n",
    "                            'neurons',\n",
    "                            'res-jb',])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "local_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
