{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from analyze_results import *\n",
    "from getting_examples import *\n",
    "from predict_activations import *\n",
    "from model_utils import *\n",
    "from utils import *\n",
    "from reVals_vs_val import *\n",
    "import json\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/feature_benchmark/feat_bench/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gpt2-small into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "sae, model = load_sae_and_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "string = ['hello there my small green friend']\n",
    "_, inner_acts, _ = get_sae_activations(model, sae, string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10.626654624938965,\n",
       " 4.0466508865356445,\n",
       " 6.337054252624512,\n",
       " 8.39116096496582,\n",
       " 6.708599090576172,\n",
       " 4.537791728973389]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_19_acts = [inner_acts[0][i][19] for i in range(len(inner_acts[0]))]\n",
    "regular_losses = get_vanilla_loss(model, sae, string)\n",
    "sae_losses = get_vanilla_loss(model, sae, string, with_sae_replacement=True)\n",
    "precomputed_zeros = [[[0.0] * len(l) for l in seq] for seq in inner_acts]\n",
    "zeros_losses = get_recons_loss_from_predicted_values(model, sae, string, precomputed_zeros)\n",
    "ablated_inner_acts = replace_feature_activation(inner_acts, 19, 0)\n",
    "ablated_feature_losses = get_recons_loss_from_predicted_values(model, sae, string, ablated_inner_acts)\n",
    "ablated_feature_losses[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[9.74209976196289,\n",
       "  11.601560592651367,\n",
       "  8.337759017944336,\n",
       "  9.623224258422852,\n",
       "  8.756343841552734,\n",
       "  9.638862609863281]]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted = [5*(18-i) for i in range(len(inner_acts[0]))]\n",
    "\n",
    "replacements = [predicted]\n",
    "replaced_inner_acts = replace_sequence_feature_activation(inner_acts, 19, replacements)\n",
    "replaced_sae_losses = get_recons_loss_from_predicted_values(model, sae, string, replaced_inner_acts)\n",
    "replaced_sae_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/96 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/96 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "IS this the problem?? 20, 17",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mget_experiment_losses\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpublic_data/subset_100_run1.json\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msae\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/feature_benchmark/analyze_results.py:43\u001b[0m, in \u001b[0;36mget_experiment_losses\u001b[0;34m(experiment_file, model, sae)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m# Loss using predicted activations\u001b[39;00m\n\u001b[1;32m     42\u001b[0m replacements \u001b[38;5;241m=\u001b[39m [example[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprediction\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[0;32m---> 43\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(inner_acts[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(replacements[\u001b[38;5;241m0\u001b[39m]), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIS this the problem?? \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(inner_acts[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(replacements[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     44\u001b[0m replaced_inner_acts \u001b[38;5;241m=\u001b[39m replace_sequence_feature_activation(inner_acts, feat_id, replacements)\n\u001b[1;32m     45\u001b[0m replaced_sae_losses \u001b[38;5;241m=\u001b[39m get_recons_loss_from_predicted_values(model, sae, sentence_string, replaced_inner_acts)\n",
      "\u001b[0;31mAssertionError\u001b[0m: IS this the problem?? 20, 17"
     ]
    }
   ],
   "source": [
    "get_experiment_losses('public_data/subset_100_run1.json', model, sae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recompute_directory_activations('6-res-jb_subset_100', 'gpt2-small-organized/6-res-jb', model, sae, recompute=False, re_sort=False, num_neg_others=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_names, mean_pos_ratio, mean_neg_ratio, num_positives = compare_recomputed_group('6-res-jb_subset_100')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2534.json pos 0.5516546720958339\n",
      "9532.json pos 0.6212932628651577\n",
      "15570.json pos 0.4686740678896811\n",
      "20780.json pos 0.342133800284376\n",
      "20780.json num pos 5\n",
      "2830.json pos 0.22913556500864662\n",
      "10404.json pos 0\n",
      "10404.json num pos 0\n",
      "8064.json pos 0.3940560582069721\n",
      "4036.json neg 0.2727272727272727\n",
      "19899.json pos 0\n",
      "19899.json num pos 0\n",
      "7739.json neg 0.16\n",
      "19484.json pos 0.5232896412076664\n",
      "14931.json pos 0.050575466759776914\n",
      "14931.json num pos 9\n",
      "22832.json pos 0.5843800777466767\n",
      "9579.json pos 0.14695032468931066\n"
     ]
    }
   ],
   "source": [
    "for file, pos, neg, num_pos in zip(file_names, mean_pos_ratio, mean_neg_ratio, num_positives):\n",
    "    if pos < 0.7:\n",
    "        print(file, 'pos', pos)\n",
    "    if neg > 0.05:\n",
    "        print(file, 'neg', neg)\n",
    "    if num_pos < 10:\n",
    "        print(file, 'num pos', num_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2350, 23251, 11000, 13627, 21896, 6332, 2534, 11263, 8913, 9532, 5128, 5157, 15162, 12092, 19697, 15570, 21983, 3230, 10322, 7428, 10949, 11451, 16697, 6750, 19453, 23607, 1346, 4730, 21772, 11817, 20963, 17386, 20351, 20820, 3096, 4634, 2830, 11212, 16183, 8064, 14882, 6448, 14583, 1103, 10075, 5625, 9760, 3594, 20189, 2004, 11264, 8685, 16693, 7476, 16596, 11799, 13133, 9658, 1202, 12694, 14524, 4036, 4679, 14073, 14372, 14610, 15500, 21032, 752, 18083, 7739, 11606, 3197, 14169, 19484, 22719, 8728, 7104, 22832, 2858, 9002, 536, 7585, 17533, 428, 19505, 6769, 2726, 13410, 22202, 3509, 9579, 681, 22138, 21380, 15824]\n"
     ]
    }
   ],
   "source": [
    "ignore_indices = [20780, 10404, 19899, 14931]\n",
    "np.random.seed(42)\n",
    "indices = list(map(int, np.random.choice(24576, size=100, replace=False)))\n",
    "indices = [i for i in indices if i not in ignore_indices]\n",
    "print(indices)\n",
    "human_indices = indices[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted 1 of 100 tasks. Been running for 12 seconds\n",
      "Submitted 2 of 100 tasks. Been running for 22 seconds\n",
      "Submitted 3 of 100 tasks. Been running for 32 seconds\n",
      "Submitted 4 of 100 tasks. Been running for 42 seconds\n",
      "Submitted 5 of 100 tasks. Been running for 52 seconds\n",
      "Warning: Resampling\n",
      "Submitted 6 of 100 tasks. Been running for 62 seconds\n",
      "Submitted 7 of 100 tasks. Been running for 72 seconds\n",
      "Submitted 8 of 100 tasks. Been running for 82 seconds\n",
      "Warning: Resampling\n",
      "Warning: Resampling\n",
      "Warning: Resampling\n",
      "Warning: Resampling\n",
      "Submitted 9 of 100 tasks. Been running for 92 seconds\n",
      "Submitted 10 of 100 tasks. Been running for 102 seconds\n",
      "Warning: Resampling\n",
      "Warning: Resampling\n",
      "WARNING: padding prediction with 2 zeros\n",
      "Warning: Resampling\n",
      "WARNING: padding prediction with 2 zeros\n",
      "Warning: Resampling\n",
      "WARNING: padding prediction with 2 zeros\n",
      "Warning: Resampling\n",
      "Submitted 11 of 100 tasks. Been running for 112 seconds\n",
      "Submitted 12 of 100 tasks. Been running for 122 seconds\n",
      "Warning: Resampling\n",
      "Submitted 13 of 100 tasks. Been running for 132 seconds\n",
      "Submitted 14 of 100 tasks. Been running for 143 seconds\n",
      "Submitted 15 of 100 tasks. Been running for 153 seconds\n",
      "Submitted 16 of 100 tasks. Been running for 163 seconds\n",
      "Warning: Resampling\n",
      "Submitted 17 of 100 tasks. Been running for 173 seconds\n",
      "Warning: Resampling\n",
      "Warning: Resampling\n",
      "WARNING: Resampling twice\n",
      "CRITICAL WARNING: No valid model prediction for \" prepared man ever to win the presidency. The mediaâĢĻs central task now and\" in 6-res-jb_subset_100/15570.json\n",
      "Warning: Resampling\n",
      "WARNING: Resampling twice\n",
      "Warning: Resampling\n",
      "Warning: Resampling\n",
      "Submitted 18 of 100 tasks. Been running for 183 seconds\n",
      "Warning: Resampling\n",
      "WARNING: padding prediction with 2 zeros\n",
      "Warning: Resampling\n",
      "WARNING: padding prediction with 2 zeros\n",
      "Warning: Resampling\n",
      "Submitted 19 of 100 tasks. Been running for 193 seconds\n",
      "Warning: Resampling\n",
      "Warning: Resampling\n",
      "Submitted 20 of 100 tasks. Been running for 203 seconds\n",
      "Warning: Resampling\n",
      "Warning: Resampling\n",
      "WARNING: padding prediction with 2 zeros\n",
      "Warning: Resampling\n",
      "Warning: Resampling\n",
      "WARNING: padding prediction with 2 zeros\n",
      "Submitted 21 of 100 tasks. Been running for 213 seconds\n",
      "Submitted 22 of 100 tasks. Been running for 223 seconds\n",
      "Submitted 23 of 100 tasks. Been running for 233 seconds\n",
      "Submitted 24 of 100 tasks. Been running for 243 seconds\n",
      "Warning: Resampling\n",
      "WARNING: padding prediction with 2 zeros\n",
      "Submitted 25 of 100 tasks. Been running for 253 seconds\n",
      "Warning: Resampling\n",
      "Warning: Resampling\n",
      "Submitted 26 of 100 tasks. Been running for 263 seconds\n",
      "Submitted 27 of 100 tasks. Been running for 273 seconds\n",
      "Warning: Resampling\n",
      "WARNING: padding prediction with 2 zeros\n",
      "Submitted 28 of 100 tasks. Been running for 283 seconds\n",
      "Submitted 29 of 100 tasks. Been running for 293 seconds\n",
      "Submitted 30 of 100 tasks. Been running for 303 seconds\n",
      "Warning: Resampling\n",
      "Submitted 31 of 100 tasks. Been running for 313 seconds\n",
      "Submitted 32 of 100 tasks. Been running for 323 seconds\n",
      "Warning: Resampling\n",
      "Submitted 33 of 100 tasks. Been running for 333 seconds\n",
      "Submitted 34 of 100 tasks. Been running for 343 seconds\n",
      "Warning: Resampling\n",
      "Submitted 35 of 100 tasks. Been running for 353 seconds\n",
      "Warning: Resampling\n",
      "Submitted 36 of 100 tasks. Been running for 363 seconds\n",
      "Warning: Resampling\n",
      "Warning: Resampling\n",
      "WARNING: padding prediction with 2 zeros\n",
      "Warning: Resampling\n",
      "Submitted 37 of 100 tasks. Been running for 373 seconds\n",
      "Warning: Resampling\n",
      "WARNING: padding prediction with 2 zeros\n",
      "Warning: Resampling\n",
      "Submitted 38 of 100 tasks. Been running for 383 seconds\n",
      "Warning: Resampling\n",
      "WARNING: padding prediction with 2 zeros\n",
      "Submitted 39 of 100 tasks. Been running for 393 seconds\n",
      "Warning: Resampling\n",
      "Submitted 40 of 100 tasks. Been running for 403 seconds\n",
      "Warning: Resampling\n",
      "WARNING: padding prediction with 2 zeros\n",
      "Warning: Resampling\n",
      "Submitted 41 of 100 tasks. Been running for 413 seconds\n",
      "Warning: Resampling\n",
      "Submitted 42 of 100 tasks. Been running for 423 seconds\n",
      "Submitted 43 of 100 tasks. Been running for 433 seconds\n",
      "Submitted 44 of 100 tasks. Been running for 443 seconds\n",
      "Warning: Resampling\n",
      "Warning: Resampling\n",
      "Warning: Resampling\n",
      "Submitted 45 of 100 tasks. Been running for 453 seconds\n",
      "Warning: Resampling\n",
      "Warning: Resampling\n",
      "Submitted 46 of 100 tasks. Been running for 463 seconds\n",
      "Warning: Resampling\n",
      "Submitted 47 of 100 tasks. Been running for 473 seconds\n",
      "Warning: Resampling\n",
      "Submitted 48 of 100 tasks. Been running for 483 seconds\n",
      "Warning: Resampling\n",
      "Warning: Resampling\n",
      "Submitted 49 of 100 tasks. Been running for 493 seconds\n",
      "Warning: Resampling\n",
      "Submitted 50 of 100 tasks. Been running for 503 seconds\n",
      "Warning: Resampling\n",
      "Submitted 51 of 100 tasks. Been running for 513 seconds\n",
      "Warning: Resampling\n",
      "WARNING: padding prediction with 2 zeros\n",
      "Warning: Resampling\n",
      "WARNING: padding prediction with 2 zeros\n",
      "Warning: Resampling\n",
      "WARNING: padding prediction with 2 zeros\n",
      "Submitted 52 of 100 tasks. Been running for 523 seconds\n",
      "Submitted 53 of 100 tasks. Been running for 533 seconds\n",
      "Submitted 54 of 100 tasks. Been running for 543 seconds\n",
      "Warning: Resampling\n",
      "Submitted 55 of 100 tasks. Been running for 553 seconds\n",
      "Submitted 56 of 100 tasks. Been running for 563 seconds\n",
      "Submitted 57 of 100 tasks. Been running for 573 seconds\n",
      "Submitted 58 of 100 tasks. Been running for 583 seconds\n",
      "Warning: Resampling\n",
      "WARNING: padding prediction with 2 zeros\n",
      "Submitted 59 of 100 tasks. Been running for 593 seconds\n",
      "Warning: Resampling\n",
      "Warning: Resampling\n",
      "Warning: Resampling\n",
      "Submitted 60 of 100 tasks. Been running for 603 seconds\n",
      "Warning: Resampling\n",
      "WARNING: padding prediction with 2 zeros\n",
      "Submitted 61 of 100 tasks. Been running for 613 seconds\n",
      "Submitted 62 of 100 tasks. Been running for 623 seconds\n",
      "Submitted 63 of 100 tasks. Been running for 633 seconds\n",
      "Submitted 64 of 100 tasks. Been running for 643 seconds\n",
      "Submitted 65 of 100 tasks. Been running for 653 seconds\n",
      "Submitted 66 of 100 tasks. Been running for 663 seconds\n",
      "Submitted 67 of 100 tasks. Been running for 673 seconds\n",
      "Warning: Resampling\n",
      "Warning: Resampling\n",
      "WARNING: padding prediction with 2 zeros\n",
      "Warning: Resampling\n",
      "Submitted 68 of 100 tasks. Been running for 683 seconds\n",
      "Submitted 69 of 100 tasks. Been running for 693 seconds\n",
      "Warning: Resampling\n",
      "Submitted 70 of 100 tasks. Been running for 703 seconds\n",
      "Submitted 71 of 100 tasks. Been running for 713 seconds\n",
      "Warning: Resampling\n",
      "Submitted 72 of 100 tasks. Been running for 723 seconds\n",
      "Submitted 73 of 100 tasks. Been running for 733 seconds\n",
      "Submitted 74 of 100 tasks. Been running for 743 seconds\n",
      "Submitted 75 of 100 tasks. Been running for 753 seconds\n",
      "Submitted 76 of 100 tasks. Been running for 763 seconds\n",
      "Warning: Resampling\n",
      "Submitted 77 of 100 tasks. Been running for 773 seconds\n",
      "Warning: Resampling\n",
      "Submitted 78 of 100 tasks. Been running for 783 seconds\n",
      "Warning: Resampling\n",
      "WARNING: padding prediction with 2 zeros\n",
      "Warning: Resampling\n",
      "WARNING: padding prediction with 2 zeros\n",
      "Submitted 79 of 100 tasks. Been running for 793 seconds\n",
      "Submitted 80 of 100 tasks. Been running for 803 seconds\n",
      "Submitted 81 of 100 tasks. Been running for 813 seconds\n",
      "Submitted 82 of 100 tasks. Been running for 823 seconds\n",
      "Warning: Resampling\n",
      "Submitted 83 of 100 tasks. Been running for 833 seconds\n",
      "Submitted 84 of 100 tasks. Been running for 843 seconds\n",
      "Submitted 85 of 100 tasks. Been running for 853 seconds\n",
      "Submitted 86 of 100 tasks. Been running for 863 seconds\n",
      "Submitted 87 of 100 tasks. Been running for 873 seconds\n",
      "Submitted 88 of 100 tasks. Been running for 883 seconds\n",
      "Submitted 89 of 100 tasks. Been running for 893 seconds\n",
      "Warning: Resampling\n",
      "Submitted 90 of 100 tasks. Been running for 903 seconds\n",
      "Warning: Resampling\n",
      "Submitted 91 of 100 tasks. Been running for 913 seconds\n",
      "Submitted 92 of 100 tasks. Been running for 923 seconds\n",
      "Submitted 93 of 100 tasks. Been running for 933 seconds\n",
      "Submitted 94 of 100 tasks. Been running for 943 seconds\n",
      "Warning: Resampling\n",
      "Submitted 95 of 100 tasks. Been running for 953 seconds\n",
      "Submitted 96 of 100 tasks. Been running for 963 seconds\n"
     ]
    }
   ],
   "source": [
    "results = run_experiments(\n",
    "    location='6-res-jb_subset_100',\n",
    "    num_features=100, \n",
    "    test_pos=10, # Experiment with\n",
    "    test_neg=10, # Experiment with\n",
    "    show_pos=0, # Experiment with\n",
    "    show_neg=0, # Experiment with\n",
    "    neg_type='others', # Experiment with\n",
    "    binary_class=False, # Experiment with\n",
    "    all_tokens=True,\n",
    "    show_max_token=False, # Experiment with\n",
    "    num_completions=5, # Experiment with\n",
    "    debug=False, \n",
    "    randomize_pos=True, \n",
    "    save_location='all_features',\n",
    "    feature_ids=indices\n",
    ")\n",
    "\n",
    "# # the run_experiments function automatically saves results to results/exp_{timestamp}.json\n",
    "# pprint.pprint(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mentions of financial funding through grants\n",
      " published this spring, was funded through a grant from NHTSA and conducted through the\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 49.51050567626953, 0.1973066926002502, 0, 0, 0, 0, 0, 0, 0]\n",
      "I. will receive a three-year grant from the Massachusetts Service Alliance that will place\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 48.00002670288086, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      " maintenance and repair.ĊĊConstruction and extraction, and management were more preferred by Generation\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "liquid GoldâĢĿ is now harder to extract in proportion to how much better the miner\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "feat_id = 1\n",
    "\n",
    "description, pos_examples, neg_examples, highest_activation = get_pos_neg_examples(feat_id, layer=6, basis='res-jb', num_pos=2, num_neg=2, neg_type='others', randomize_pos_examples=False)\n",
    "print(description)\n",
    "\n",
    "max_indices = [pos_examples[i]['max_value_token_index'] + 1 for i in range(len(pos_examples))] + [9 for i in range(len(neg_examples))]\n",
    "strings = [pos_examples[i]['sentence_string'] for i in range(len(pos_examples))] + [neg_examples[i]['sentence_string'] for i in range(len(neg_examples))]\n",
    "\n",
    "for pos in pos_examples:\n",
    "    print(pos['sentence_string'])\n",
    "    print(pos['values'])\n",
    "\n",
    "for neg in neg_examples:\n",
    "    print(neg['sentence_string'])\n",
    "    print(neg['values'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.         48.49956131  1.33336258  0.\n",
      "  0.          0.          0.          0.          0.          0.        ]\n",
      "[ 0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.         42.76519775  0.          0.\n",
      "  0.          0.          0.          0.          0.          0.        ]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "pre_acts, inner_acts, post_acts = get_sae_activations(model, sae, strings)\n",
    "\n",
    "for inner_act in inner_acts:\n",
    "    x = np.array(inner_act)\n",
    "    print(x[:,feat_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regular losses:\n",
      " published this spring, was funded through a grant from NHTSA and conducted through the (4.1803): 13.6845 6.9317 6.7337 2.1646 5.5099 5.8693 3.7500 1.0739 2.1365 0.1572 6.3267 4.8857 0.0050 2.3500 5.8504 2.4335 1.2026\n",
      "I. will receive a three-year grant from the Massachusetts Service Alliance that will place (4.7467): 3.9997 6.1135 11.2789 7.5890 1.7388 7.5961 0.6220 2.4118 5.1721 1.0106 0.4074 5.7994 9.1498 5.7121 3.7558 0.5996 7.7381\n",
      " maintenance and repair.ĊĊConstruction and extraction, and management were more preferred by Generation (6.6791): 15.5910 3.6142 3.4101 3.3890 13.1244 5.9245 4.1812 0.6081 12.4337 2.8099 7.9760 3.7875 3.3171 5.7862 8.2974 7.8089 10.2664 3.6485 10.9288\n",
      "liquid GoldâĢĿ is now harder to extract in proportion to how much better the miner (6.1832): 11.8105 11.7301 14.0158 7.4184 6.0638 3.9871 7.3467 6.3138 5.2734 9.7803 0.3941 4.5342 3.9772 8.5973 0.1226 4.5083 0.3920 8.0369 2.1290 7.2319\n",
      "SAE losses:\n",
      " published this spring, was funded through a grant from NHTSA and conducted through the (4.1995): 13.7159 5.8250 7.5830 1.0363 5.8370 7.0606 3.2471 1.2248 2.1267 0.3422 6.6113 4.4166 0.2100 2.4070 5.8228 2.7563 1.1680\n",
      "I. will receive a three-year grant from the Massachusetts Service Alliance that will place (4.7523): 4.0963 5.9176 10.0126 7.4673 1.9837 7.4549 0.4112 1.9489 5.1028 1.0288 0.6698 6.3484 9.1827 6.5538 4.3308 0.8622 7.4177\n",
      " maintenance and repair.ĊĊConstruction and extraction, and management were more preferred by Generation (6.7188): 15.6880 3.7076 3.9394 3.5226 13.0648 6.0707 3.1389 2.6757 13.8095 3.2645 8.0783 3.8995 3.2487 5.9011 8.1065 6.7553 8.4807 3.4476 10.8584\n",
      "liquid GoldâĢĿ is now harder to extract in proportion to how much better the miner (6.0971): 11.7411 10.5847 13.4746 8.2948 5.8304 3.8520 7.7078 5.9872 5.4499 9.9195 0.6567 4.8825 4.1477 8.8427 0.1153 4.4879 0.8287 5.6379 2.4252 7.0759\n",
      "Zeros losses:\n",
      " published this spring, was funded through a grant from NHTSA and conducted through the (8.6929): 9.7256 7.3141 10.6736 2.3919 7.9510 12.9913 5.9910 4.6239 10.9653 6.5388 10.9766 15.3514 19.6931 2.3378 9.0870 5.9910 5.1758\n",
      "I. will receive a three-year grant from the Massachusetts Service Alliance that will place (9.3040): 12.6561 1.9816 8.2481 10.3467 4.6239 8.8132 6.0656 14.0043 10.9653 6.5388 5.1758 14.6507 13.7828 17.5590 5.6262 8.2481 8.8816\n",
      " maintenance and repair.ĊĊConstruction and extraction, and management were more preferred by Generation (10.4624): 12.1786 2.3378 12.2979 1.9816 16.9512 20.1063 16.9512 20.1063 23.0904 2.3378 15.1371 2.3919 2.3378 9.9884 8.1715 5.1455 11.6562 3.1297 12.4874\n",
      "liquid GoldâĢĿ is now harder to extract in proportion to how much better the miner (11.3845): 17.4550 15.8902 17.0953 16.9512 22.9173 16.9512 19.8813 6.1830 7.9132 10.6944 3.8188 12.7693 4.4210 8.9364 3.8188 6.0763 6.4067 9.1289 5.1758 15.2053\n"
     ]
    }
   ],
   "source": [
    "# Get model's loss on strings\n",
    "regular_losses = get_vanilla_loss(model, sae, strings)\n",
    "print(pretty_losses_fmt(\"Regular\", strings, regular_losses))\n",
    "\n",
    "# Get model's loss on strings using SAE reconstructed activations\n",
    "sae_losses = get_vanilla_loss(model, sae, strings, with_sae_replacement=True)\n",
    "print(pretty_losses_fmt(\"SAE\", strings, sae_losses))\n",
    "\n",
    "# Loss with all features ablated\n",
    "precomputed_zeros = [[[0.0] * len(l) for l in seq] for seq in inner_acts]\n",
    "zeros_losses = get_recons_loss_from_predicted_values(model, sae, strings, precomputed_zeros)\n",
    "print(pretty_losses_fmt(\"Zeros\", strings, zeros_losses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAE feature 1 ablated losses:\n",
      " published this spring, was funded through a grant from NHTSA and conducted through the (4.2348): 13.7159 5.8250 7.5830 1.0363 5.8370 7.0606 3.2471 1.2248 2.1267 0.7712 6.5461 4.4802 0.2106 2.4924 5.8819 2.7817 1.1709\n",
      "I. will receive a three-year grant from the Massachusetts Service Alliance that will place (4.7978): 4.0963 5.9176 10.0126 7.4673 1.9837 7.4549 0.4112 1.9489 5.1028 1.6349 0.8448 6.5888 9.1750 6.6881 4.3267 0.9515 6.9573\n",
      " maintenance and repair.ĊĊConstruction and extraction, and management were more preferred by Generation (6.7188): 15.6880 3.7076 3.9394 3.5226 13.0648 6.0707 3.1389 2.6757 13.8095 3.2645 8.0783 3.8995 3.2487 5.9011 8.1065 6.7553 8.4807 3.4476 10.8584\n",
      "liquid GoldâĢĿ is now harder to extract in proportion to how much better the miner (6.0971): 11.7411 10.5847 13.4746 8.2948 5.8304 3.8520 7.7078 5.9872 5.4499 9.9195 0.6567 4.8825 4.1477 8.8427 0.1153 4.4879 0.8287 5.6379 2.4252 7.0759\n",
      "[0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         1.33336258 0.\n",
      " 0.         0.         0.         0.         0.         0.        ]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.43, -0.07, 0.06, 0.0, 0.09, 0.06, 0.03, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.61, 0.17, 0.24, -0.01, 0.13, -0.0, 0.09, -0.46], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]]\n"
     ]
    }
   ],
   "source": [
    "# Get model's loss on strings using SAE with selected feature ablated\n",
    "replacements = [0 for string in strings]\n",
    "ablated_inner_acts = replace_max_feature_activation(inner_acts, feat_id, max_indices, replacements)\n",
    "ablated_sae_losses = get_recons_loss_from_predicted_values(model, sae, strings, ablated_inner_acts)\n",
    "print(pretty_losses_fmt(f\"SAE feature {feat_id} ablated\", strings, ablated_sae_losses))\n",
    "\n",
    "for inner_act in ablated_inner_acts:\n",
    "    x = np.array(inner_act)\n",
    "    print(x[:,feat_id])\n",
    "\n",
    "# Print how much loss changes after ablating selected feature\n",
    "difference = elementwise_difference(sae_losses, ablated_sae_losses)\n",
    "rounded_difference = [[round(elem, 2) for elem in sublist] for sublist in difference]\n",
    "print(rounded_difference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are evaluating an english description of an autoencoder feature. The description should correspond to sentences which result in high activation. The english description of the feature is: \"occurrences of the word \"try\"\"\n",
      "The feature will tend to have zero activation on most tokens, but may activate highly on one or a few tokens in the sentence that correspond to the provided description.\n",
      "The value of the highest activation on the dataset is 54.67. Almost all tokens in almost all sequences have an activation of zero, while a few tokens that exactly match the provided description may have higher activations (somewhere between 0 and 54.67). You must predict the activations for each token a new sentence based off of the provided description. \n",
      "You MUST respond with a list of numbers, one for each token in the sequence, and NO OTHER content.\n",
      "Please predict the activation on this sentence,responding with a list of 17 numbers between 0 and 54.67.\n",
      "Sentence: \" See our privacy notice Could not subscribe, try again later Invalid EmailĊĊANGR\"\n",
      "Tokens:\n",
      " See\n",
      " our\n",
      " privacy\n",
      " notice\n",
      " Could\n",
      " not\n",
      " subscribe\n",
      ",\n",
      " try\n",
      " again\n",
      " later\n",
      " Invalid\n",
      " Email\n",
      "Ċ\n",
      "Ċ\n",
      "AN\n",
      "GR\n",
      "Remember, the english description of the feature is: \"occurrences of the word \"try\"\"\n",
      "Model response: 0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "33.45\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "Parsed response: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 33.45, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Model response: 0, 0, 0, 0, 0, 0, 0, 0, 40.12, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "Parsed response: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.12, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Model response: 0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "17.34\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "Parsed response: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 17.34, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 49.46665954589844, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.30333333333333, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Please predict the activation on this sentence,responding with a list of 17 numbers between 0 and 54.67.\n",
      "Sentence: \" See our privacy notice Could not subscribe, try again later Invalid EmailĊĊAn object\"\n",
      "Tokens:\n",
      " See\n",
      " our\n",
      " privacy\n",
      " notice\n",
      " Could\n",
      " not\n",
      " subscribe\n",
      ",\n",
      " try\n",
      " again\n",
      " later\n",
      " Invalid\n",
      " Email\n",
      "Ċ\n",
      "Ċ\n",
      "An\n",
      " object\n",
      "Remember, the english description of the feature is: \"occurrences of the word \"try\"\"\n",
      "Model response: 0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "54.67\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "Parsed response: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 54.67, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Model response: 0, 0, 0, 0, 0, 0, 0, 0, 36.21, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "Parsed response: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 36.21, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Model response: 0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "54.67\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "Parsed response: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 54.67, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 49.46665954589844, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 48.51666666666667, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Please predict the activation on this sentence,responding with a list of 17 numbers between 0 and 54.67.\n",
      "Sentence: \" See our privacy notice Could not subscribe, try again later Invalid EmailĊĊLady Gaga\"\n",
      "Tokens:\n",
      " See\n",
      " our\n",
      " privacy\n",
      " notice\n",
      " Could\n",
      " not\n",
      " subscribe\n",
      ",\n",
      " try\n",
      " again\n",
      " later\n",
      " Invalid\n",
      " Email\n",
      "Ċ\n",
      "Ċ\n",
      "Lady\n",
      " Gaga\n",
      "Remember, the english description of the feature is: \"occurrences of the word \"try\"\"\n",
      "Model response: 0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "25.67\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "Parsed response: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 25.67, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Model response: 0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "54.67\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "Parsed response: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 54.67, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Model response: 0, 0, 0, 0, 0, 0, 0, 0, 27.12, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "Parsed response: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 27.12, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 49.46665954589844, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 35.82, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Please predict the activation on this sentence,responding with a list of 17 numbers between 0 and 54.67.\n",
      "Sentence: \" subscribing. An error has occurred. Please try again later. View all New York Times\"\n",
      "Tokens:\n",
      " subscribing\n",
      ".\n",
      " An\n",
      " error\n",
      " has\n",
      " occurred\n",
      ".\n",
      " Please\n",
      " try\n",
      " again\n",
      " later\n",
      ".\n",
      " View\n",
      " all\n",
      " New\n",
      " York\n",
      " Times\n",
      "Remember, the english description of the feature is: \"occurrences of the word \"try\"\"\n",
      "Model response: 0, 0, 0, 0, 0, 0, 0, 0, 32.45, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "Parsed response: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 32.45, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Model response: [0, 0, 0, 0, 0, 0, 0, 0, 54.67, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Parsed response: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 54.67, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Model response: [0, 0, 0, 0, 0, 0, 0, 0, 54.67, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Parsed response: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 54.67, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.04263687133789, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 47.26333333333334, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Please predict the activation on this sentence,responding with a list of 17 numbers between 0 and 54.67.\n",
      "Sentence: \" See our privacy notice Could not subscribe, try again later Invalid EmailĊĊSerg\"\n",
      "Tokens:\n",
      " See\n",
      " our\n",
      " privacy\n",
      " notice\n",
      " Could\n",
      " not\n",
      " subscribe\n",
      ",\n",
      " try\n",
      " again\n",
      " later\n",
      " Invalid\n",
      " Email\n",
      "Ċ\n",
      "Ċ\n",
      "S\n",
      "erg\n",
      "Remember, the english description of the feature is: \"occurrences of the word \"try\"\"\n",
      "Model response: 0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "54.67\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "Parsed response: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 54.67, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Model response: 0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "23.54\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "Parsed response: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.54, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Model response: 0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "27.33\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "Parsed response: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 27.33, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 49.46665954589844, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 35.18, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Please predict the activation on this sentence,responding with a list of 17 numbers between 0 and 54.67.\n",
      "Sentence: \" biggest economic downturn since the Great Depression and at odds over how big a role government should\"\n",
      "Tokens:\n",
      " biggest\n",
      " economic\n",
      " downturn\n",
      " since\n",
      " the\n",
      " Great\n",
      " Depression\n",
      " and\n",
      " at\n",
      " odds\n",
      " over\n",
      " how\n",
      " big\n",
      " a\n",
      " role\n",
      " government\n",
      " should\n",
      "Remember, the english description of the feature is: \"occurrences of the word \"try\"\"\n",
      "Model response: 0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "Parsed response: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Model response: 0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "Parsed response: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Model response: 0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "Parsed response: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Please predict the activation on this sentence,responding with a list of 17 numbers between 0 and 54.67.\n",
      "Sentence: \" on Sugarloaf Parkway Wednesday for traffic violations, but said Hollins resisted arrest.\"\n",
      "Tokens:\n",
      " on\n",
      " Sugar\n",
      "lo\n",
      "af\n",
      " Parkway\n",
      " Wednesday\n",
      " for\n",
      " traffic\n",
      " violations\n",
      ",\n",
      " but\n",
      " said\n",
      " Holl\n",
      "ins\n",
      " resisted\n",
      " arrest\n",
      ".\n",
      "Remember, the english description of the feature is: \"occurrences of the word \"try\"\"\n",
      "Model response: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 54.67, 0\n",
      "Parsed response: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 54.67, 0.0]\n",
      "Model response: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "Parsed response: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Model response: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "Parsed response: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 18.223333333333333, 0.0]\n",
      "Please predict the activation on this sentence,responding with a list of 17 numbers between 0 and 54.67.\n",
      "Sentence: \" Game Boy Color (the latter is the version on Virtual Console), could be termed as\"\n",
      "Tokens:\n",
      " Game\n",
      " Boy\n",
      " Color\n",
      " (\n",
      "the\n",
      " latter\n",
      " is\n",
      " the\n",
      " version\n",
      " on\n",
      " Virtual\n",
      " Console\n",
      "),\n",
      " could\n",
      " be\n",
      " termed\n",
      " as\n",
      "Remember, the english description of the feature is: \"occurrences of the word \"try\"\"\n",
      "Model response: 0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "Parsed response: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Model response: 0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "Parsed response: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0]\n",
      "Model response: 0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "Parsed response: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Please predict the activation on this sentence,responding with a list of 17 numbers between 0 and 54.67.\n",
      "Sentence: \"leton College Carleton University Carnegie Mellon University Case Western Reserve University Catholic University of America Centre\"\n",
      "Tokens:\n",
      "leton\n",
      " College\n",
      " Car\n",
      "leton\n",
      " University\n",
      " Carnegie\n",
      " Mellon\n",
      " University\n",
      " Case\n",
      " Western\n",
      " Reserve\n",
      " University\n",
      " Catholic\n",
      " University\n",
      " of\n",
      " America\n",
      " Centre\n",
      "Remember, the english description of the feature is: \"occurrences of the word \"try\"\"\n",
      "Model response: [0, 0, 0, 54.67, 0, 0, 0, 0, 0, 0, 0, 54.67, 0, 0, 0, 0, 0]\n",
      "Parsed response: [0.0, 0.0, 0.0, 54.67, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 54.67, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Model response: 0, 0, 0, 24.67, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "Parsed response: [0.0, 0.0, 0.0, 24.67, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Model response: 0, 0, 0, 54.67, 0, 0, 0, 54.67, 0, 0, 0, 54.67, 0, 0, 0, 0, 0\n",
      "Parsed response: [0.0, 0.0, 0.0, 54.67, 0.0, 0.0, 0.0, 54.67, 0.0, 0.0, 0.0, 54.67, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] [0.0, 0.0, 0.0, 44.669999999999995, 0.0, 0.0, 0.0, 18.223333333333333, 0.0, 0.0, 0.0, 36.446666666666665, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Please predict the activation on this sentence,responding with a list of 17 numbers between 0 and 54.67.\n",
      "Sentence: \" entrepreneurs have sold their businesses and Western students have stayed away from China.ĊĊFal\"\n",
      "Tokens:\n",
      " entrepreneurs\n",
      " have\n",
      " sold\n",
      " their\n",
      " businesses\n",
      " and\n",
      " Western\n",
      " students\n",
      " have\n",
      " stayed\n",
      " away\n",
      " from\n",
      " China\n",
      ".\n",
      "Ċ\n",
      "Ċ\n",
      "Fal\n",
      "Remember, the english description of the feature is: \"occurrences of the word \"try\"\"\n",
      "Model response: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "Parsed response: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Model response: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "Parsed response: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Model response: 0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "Parsed response: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "predictions = predict_activations('6-res-jb_subset_100/681.json', test_pos=5, test_neg=5, show_pos=0, show_neg=0, binary_class=False, all_tokens=True, neg_type='others', show_max_token=False, num_completions=3, debug=True, randomize_pos=False, model=\"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n",
      "19\n",
      "17\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[' See',\n",
       " ' our',\n",
       " ' privacy',\n",
       " ' notice',\n",
       " ' Could',\n",
       " ' not',\n",
       " ' subscribe',\n",
       " ',',\n",
       " ' try',\n",
       " ' again',\n",
       " ' later',\n",
       " ' Invalid',\n",
       " ' Email',\n",
       " 'Ċ',\n",
       " 'Ċ',\n",
       " 'An',\n",
       " ' object']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(predictions[1]['tokens']))\n",
    "print(len(predictions[1]['values']))\n",
    "print(len(predictions[1]['prediction']))\n",
    "predictions[1]['tokens']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n",
      "19\n",
      "17\n",
      "[' See', ' our', ' privacy', ' notice', ' Could', ' not', ' subscribe', ',', ' try', ' again', ' later', ' Invalid', ' Email', 'Ċ', 'Ċ', 'An', ' object']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 49.46665954589844,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('6-res-jb_subset_100/681.json', 'r') as file:\n",
    "    data = json.load(file)\n",
    "print(len(data['posActivations'][1]['values']))\n",
    "print(len(data['posActivations'][1]['recomputedValues'][1:]))\n",
    "print(len(data['posActivations'][1]['tokens']))\n",
    "print(data['posActivations'][1]['tokens'])\n",
    "data['posActivations'][1]['values']\n",
    "data['posActivations'][1]['recomputedValues'][1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' See our privacy notice Could not subscribe, try again later Invalid EmailĊĊAn object']\n"
     ]
    }
   ],
   "source": [
    "strings = []\n",
    "strings.append(''.join(data['posActivations'][1]['tokens']))\n",
    "print(strings)\n",
    "_, inner_acts, _ = get_sae_activations(model, sae, strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(inner_acts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "f_19_acts = [x[19] for x in inner_acts[0]]\n",
    "print(f_19_acts)\n",
    "print(len(f_19_acts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = model.to_tokens(\n",
    "            [strings[0]],\n",
    "            truncate=True,\n",
    "            prepend_bos=sae.cfg.prepend_bos,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[50256,  4091,   674,  6782,  4003, 10347,   407, 12383,    11,  1949,\n",
       "           757,  1568, 17665,  9570,   128,   232,   128,   232,  2025,  2134]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|endoftext|>\n",
      " See\n",
      " our\n",
      " privacy\n",
      " notice\n",
      " Could\n",
      " not\n",
      " subscribe\n",
      ",\n",
      " try\n",
      " again\n",
      " later\n",
      " Invalid\n",
      " Email\n",
      "�\n",
      "�\n",
      "�\n",
      "�\n",
      "An\n",
      " object\n"
     ]
    }
   ],
   "source": [
    "for t in x[0]:\n",
    "    print(model.tokenizer.decode(t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run an experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do analysis on loaded json_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_data_binary = load_json_results('results/binary_test/exp_binary_others.json')\n",
    "json_data_continuous = load_json_results('results/binary_test/exp_continuous_others.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_preds = [json_data_binary['results'][i]['gpt_predictions'] for i in range(len(json_data_binary['results']))]\n",
    "continuous_preds = [json_data_continuous['results'][i]['gpt_predictions'] for i in range(len(json_data_continuous['results']))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = get_binary_accuracy(binary_preds, plot_cdf=True, plot_distribution=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_descs = get_accuracy_descs(json_data_binary, include_pos_neg=True, display=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resave_organized_modeldata(autoencoder_layers = [6],\n",
    "                        autoencoder_bases = [\n",
    "                            'neurons',\n",
    "                            'res-jb',])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "local_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
