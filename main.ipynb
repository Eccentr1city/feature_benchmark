{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from analyze_results import *\n",
    "from getting_examples import *\n",
    "from predict_activations import *\n",
    "from model_utils import *\n",
    "from utils import *\n",
    "from reVals_vs_val import *\n",
    "import json\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/feature_benchmark/feat_bench/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gpt2-small into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "sae, model = load_sae_and_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recompute_directory_activations('6-res-jb_subset_100', 'gpt2-small-organized/6-res-jb', model, sae, recompute=False, re_sort=False, num_neg_others=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_names, mean_pos_ratio, mean_neg_ratio = compare_recomputed_group('6-res-jb_subset_100')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2534.json pos 0.5422101798848261\n",
      "9532.json pos 0.6332970320399793\n",
      "15570.json pos 0.4724053762692831\n",
      "20780.json pos 0.342133800284376\n",
      "2830.json pos 0.22913556500864662\n",
      "10404.json pos 0\n",
      "8064.json pos 0.3940560582069721\n",
      "4036.json neg 0.2727272727272727\n",
      "19899.json pos 0\n",
      "7739.json neg 0.16\n",
      "19484.json pos 0.5232896412076664\n",
      "14931.json pos 0.050575466759776914\n",
      "22832.json pos 0.5843800777466767\n",
      "9579.json pos 0.14695032468931066\n"
     ]
    }
   ],
   "source": [
    "for file, pos, neg in zip(file_names, mean_pos_ratio, mean_neg_ratio):\n",
    "    if pos < 0.7:\n",
    "        print(file, 'pos', pos)\n",
    "    if neg > 0.05:\n",
    "        print(file, 'neg', neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mentions of financial funding through grants\n",
      " published this spring, was funded through a grant from NHTSA and conducted through the\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 49.51050567626953, 0.1973066926002502, 0, 0, 0, 0, 0, 0, 0]\n",
      "I. will receive a three-year grant from the Massachusetts Service Alliance that will place\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 48.00002670288086, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      " maintenance and repair.ĊĊConstruction and extraction, and management were more preferred by Generation\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "liquid GoldâĢĿ is now harder to extract in proportion to how much better the miner\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "feat_id = 1\n",
    "\n",
    "description, pos_examples, neg_examples, highest_activation = get_pos_neg_examples(feat_id, layer=6, basis='res-jb', num_pos=2, num_neg=2, neg_type='others', randomize_pos_examples=False)\n",
    "print(description)\n",
    "\n",
    "max_indices = [pos_examples[i]['max_value_token_index'] + 1 for i in range(len(pos_examples))] + [9 for i in range(len(neg_examples))]\n",
    "strings = [pos_examples[i]['sentence_string'] for i in range(len(pos_examples))] + [neg_examples[i]['sentence_string'] for i in range(len(neg_examples))]\n",
    "\n",
    "for pos in pos_examples:\n",
    "    print(pos['sentence_string'])\n",
    "    print(pos['values'])\n",
    "\n",
    "for neg in neg_examples:\n",
    "    print(neg['sentence_string'])\n",
    "    print(neg['values'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.         48.49956131  1.33336258  0.\n",
      "  0.          0.          0.          0.          0.          0.        ]\n",
      "[ 0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.         42.76519775  0.          0.\n",
      "  0.          0.          0.          0.          0.          0.        ]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "pre_acts, inner_acts, post_acts = get_sae_activations(model, sae, strings)\n",
    "\n",
    "for inner_act in inner_acts:\n",
    "    x = np.array(inner_act)\n",
    "    print(x[:,feat_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regular losses:\n",
      " published this spring, was funded through a grant from NHTSA and conducted through the (4.1803): 13.6845 6.9317 6.7337 2.1646 5.5099 5.8693 3.7500 1.0739 2.1365 0.1572 6.3267 4.8857 0.0050 2.3500 5.8504 2.4335 1.2026\n",
      "I. will receive a three-year grant from the Massachusetts Service Alliance that will place (4.7467): 3.9997 6.1135 11.2789 7.5890 1.7388 7.5961 0.6220 2.4118 5.1721 1.0106 0.4074 5.7994 9.1498 5.7121 3.7558 0.5996 7.7381\n",
      " maintenance and repair.ĊĊConstruction and extraction, and management were more preferred by Generation (6.6791): 15.5910 3.6142 3.4101 3.3890 13.1244 5.9245 4.1812 0.6081 12.4337 2.8099 7.9760 3.7875 3.3171 5.7862 8.2974 7.8089 10.2664 3.6485 10.9288\n",
      "liquid GoldâĢĿ is now harder to extract in proportion to how much better the miner (6.1832): 11.8105 11.7301 14.0158 7.4184 6.0638 3.9871 7.3467 6.3138 5.2734 9.7803 0.3941 4.5342 3.9772 8.5973 0.1226 4.5083 0.3920 8.0369 2.1290 7.2319\n",
      "SAE losses:\n",
      " published this spring, was funded through a grant from NHTSA and conducted through the (4.1995): 13.7159 5.8250 7.5830 1.0363 5.8370 7.0606 3.2471 1.2248 2.1267 0.3422 6.6113 4.4166 0.2100 2.4070 5.8228 2.7563 1.1680\n",
      "I. will receive a three-year grant from the Massachusetts Service Alliance that will place (4.7523): 4.0963 5.9176 10.0126 7.4673 1.9837 7.4549 0.4112 1.9489 5.1028 1.0288 0.6698 6.3484 9.1827 6.5538 4.3308 0.8622 7.4177\n",
      " maintenance and repair.ĊĊConstruction and extraction, and management were more preferred by Generation (6.7188): 15.6880 3.7076 3.9394 3.5226 13.0648 6.0707 3.1389 2.6757 13.8095 3.2645 8.0783 3.8995 3.2487 5.9011 8.1065 6.7553 8.4807 3.4476 10.8584\n",
      "liquid GoldâĢĿ is now harder to extract in proportion to how much better the miner (6.0971): 11.7411 10.5847 13.4746 8.2948 5.8304 3.8520 7.7078 5.9872 5.4499 9.9195 0.6567 4.8825 4.1477 8.8427 0.1153 4.4879 0.8287 5.6379 2.4252 7.0759\n",
      "Zeros losses:\n",
      " published this spring, was funded through a grant from NHTSA and conducted through the (8.6929): 9.7256 7.3141 10.6736 2.3919 7.9510 12.9913 5.9910 4.6239 10.9653 6.5388 10.9766 15.3514 19.6931 2.3378 9.0870 5.9910 5.1758\n",
      "I. will receive a three-year grant from the Massachusetts Service Alliance that will place (9.3040): 12.6561 1.9816 8.2481 10.3467 4.6239 8.8132 6.0656 14.0043 10.9653 6.5388 5.1758 14.6507 13.7828 17.5590 5.6262 8.2481 8.8816\n",
      " maintenance and repair.ĊĊConstruction and extraction, and management were more preferred by Generation (10.4624): 12.1786 2.3378 12.2979 1.9816 16.9512 20.1063 16.9512 20.1063 23.0904 2.3378 15.1371 2.3919 2.3378 9.9884 8.1715 5.1455 11.6562 3.1297 12.4874\n",
      "liquid GoldâĢĿ is now harder to extract in proportion to how much better the miner (11.3845): 17.4550 15.8902 17.0953 16.9512 22.9173 16.9512 19.8813 6.1830 7.9132 10.6944 3.8188 12.7693 4.4210 8.9364 3.8188 6.0763 6.4067 9.1289 5.1758 15.2053\n"
     ]
    }
   ],
   "source": [
    "# Get model's loss on strings\n",
    "regular_losses = get_vanilla_loss(model, sae, strings)\n",
    "print(pretty_losses_fmt(\"Regular\", strings, regular_losses))\n",
    "\n",
    "# Get model's loss on strings using SAE reconstructed activations\n",
    "sae_losses = get_vanilla_loss(model, sae, strings, with_sae_replacement=True)\n",
    "print(pretty_losses_fmt(\"SAE\", strings, sae_losses))\n",
    "\n",
    "# Loss with all features ablated\n",
    "precomputed_zeros = [[[0.0] * len(l) for l in seq] for seq in inner_acts]\n",
    "zeros_losses = get_recons_loss_from_predicted_values(model, sae, strings, precomputed_zeros)\n",
    "print(pretty_losses_fmt(\"Zeros\", strings, zeros_losses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAE feature 1 ablated losses:\n",
      " published this spring, was funded through a grant from NHTSA and conducted through the (4.2348): 13.7159 5.8250 7.5830 1.0363 5.8370 7.0606 3.2471 1.2248 2.1267 0.7712 6.5461 4.4802 0.2106 2.4924 5.8819 2.7817 1.1709\n",
      "I. will receive a three-year grant from the Massachusetts Service Alliance that will place (4.7978): 4.0963 5.9176 10.0126 7.4673 1.9837 7.4549 0.4112 1.9489 5.1028 1.6349 0.8448 6.5888 9.1750 6.6881 4.3267 0.9515 6.9573\n",
      " maintenance and repair.ĊĊConstruction and extraction, and management were more preferred by Generation (6.7188): 15.6880 3.7076 3.9394 3.5226 13.0648 6.0707 3.1389 2.6757 13.8095 3.2645 8.0783 3.8995 3.2487 5.9011 8.1065 6.7553 8.4807 3.4476 10.8584\n",
      "liquid GoldâĢĿ is now harder to extract in proportion to how much better the miner (6.0971): 11.7411 10.5847 13.4746 8.2948 5.8304 3.8520 7.7078 5.9872 5.4499 9.9195 0.6567 4.8825 4.1477 8.8427 0.1153 4.4879 0.8287 5.6379 2.4252 7.0759\n",
      "[0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         1.33336258 0.\n",
      " 0.         0.         0.         0.         0.         0.        ]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.43, -0.07, 0.06, 0.0, 0.09, 0.06, 0.03, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.61, 0.17, 0.24, -0.01, 0.13, -0.0, 0.09, -0.46], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]]\n"
     ]
    }
   ],
   "source": [
    "# Get model's loss on strings using SAE with selected feature ablated\n",
    "replacements = [0 for string in strings]\n",
    "ablated_inner_acts = replace_max_feature_activation(inner_acts, feat_id, max_indices, replacements)\n",
    "ablated_sae_losses = get_recons_loss_from_predicted_values(model, sae, strings, ablated_inner_acts)\n",
    "print(pretty_losses_fmt(f\"SAE feature {feat_id} ablated\", strings, ablated_sae_losses))\n",
    "\n",
    "for inner_act in ablated_inner_acts:\n",
    "    x = np.array(inner_act)\n",
    "    print(x[:,feat_id])\n",
    "\n",
    "# Print how much loss changes after ablating selected feature\n",
    "difference = elementwise_difference(sae_losses, ablated_sae_losses)\n",
    "rounded_difference = [[round(elem, 2) for elem in sublist] for sublist in difference]\n",
    "print(rounded_difference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "indices = list(map(int, np.random.choice(24576, size=100, replace=False)))\n",
    "print(indices)\n",
    "# copy_files_by_list(indices, 'gpt2-small-organized/6-res-jb', '6-res-jb_subset_100')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are evaluating an english description of an autoencoder feature. The description should correspond to sentences which result in high activation. The english description of the feature is: \"occurrences of the word \"try\"\"\n",
      "The feature will tend to have zero activation on most tokens, but may activate highly on one or a few tokens in the sentence that correspond to the provided description.\n",
      "The value of the highest activation on the dataset is 54.67. Almost all tokens in almost all sequences have an activation of zero, while a few tokens that exactly match the provided description may have higher activations (somewhere between 0 and 54.67). You must predict the activations for each token a new sentence based off of the provided description. \n",
      "You MUST respond with a list of numbers, one for each token in the sequence, and NO OTHER content.\n",
      "Please predict the activation on this sentence,responding with a list of 17 numbers between 0 and 54.67.\n",
      "Sentence: \" See our privacy notice Could not subscribe, try again later Invalid EmailĊĊSerg\"\n",
      "Tokens:\n",
      " See\n",
      " our\n",
      " privacy\n",
      " notice\n",
      " Could\n",
      " not\n",
      " subscribe\n",
      ",\n",
      " try\n",
      " again\n",
      " later\n",
      " Invalid\n",
      " Email\n",
      "Ċ\n",
      "Ċ\n",
      "S\n",
      "erg\n",
      "Remember, the english description of the feature is: \"occurrences of the word \"try\"\"\n",
      "Model response: 0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "18.62\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "Parsed response: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 18.62, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Model response: 0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "27.12\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "Parsed response: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 27.12, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Model response: 0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "54.67\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "Parsed response: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 54.67, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 49.46665954589844, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 33.47, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Please predict the activation on this sentence,responding with a list of 17 numbers between 0 and 54.67.\n",
      "Sentence: \" you think you had a rough childhood? Try having a gun pointed to your head by\"\n",
      "Tokens:\n",
      " you\n",
      " think\n",
      " you\n",
      " had\n",
      " a\n",
      " rough\n",
      " childhood\n",
      "?\n",
      " Try\n",
      " having\n",
      " a\n",
      " gun\n",
      " pointed\n",
      " to\n",
      " your\n",
      " head\n",
      " by\n",
      "Remember, the english description of the feature is: \"occurrences of the word \"try\"\"\n",
      "Model response: 0, 0, 0, 0, 0, 0, 0, 0, 54.67, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "Parsed response: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 54.67, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Model response: 0, 0, 0, 0, 0, 0, 0, 0, 27.12, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "Parsed response: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 27.12, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Model response: 0,0,0,0,0,0,0,0,54.67,0,0,0,0,0,0,0,0\n",
      "Parsed response: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 54.67, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 17.077308654785156, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 45.48666666666667, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Please predict the activation on this sentence,responding with a list of 17 numbers between 0 and 54.67.\n",
      "Sentence: \" See our privacy notice Could not subscribe, try again later Invalid EmailĊĊA boy\"\n",
      "Tokens:\n",
      " See\n",
      " our\n",
      " privacy\n",
      " notice\n",
      " Could\n",
      " not\n",
      " subscribe\n",
      ",\n",
      " try\n",
      " again\n",
      " later\n",
      " Invalid\n",
      " Email\n",
      "Ċ\n",
      "Ċ\n",
      "A\n",
      " boy\n",
      "Remember, the english description of the feature is: \"occurrences of the word \"try\"\"\n",
      "Model response: 0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "54.67\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "Parsed response: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 54.67, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Model response: 0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "54.67\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "Parsed response: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 54.67, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Model response: 0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "54.67\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "Parsed response: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 54.67, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 49.46665954589844, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 54.669999999999995, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Please predict the activation on this sentence,responding with a list of 17 numbers between 0 and 54.67.\n",
      "Sentence: \" here Oops. Something went wrong. Please try again later. Try again Thank you,\"\n",
      "Tokens:\n",
      " here\n",
      " Oops\n",
      ".\n",
      " Something\n",
      " went\n",
      " wrong\n",
      ".\n",
      " Please\n",
      " try\n",
      " again\n",
      " later\n",
      ".\n",
      " Try\n",
      " again\n",
      " Thank\n",
      " you\n",
      ",\n",
      "Remember, the english description of the feature is: \"occurrences of the word \"try\"\"\n",
      "Model response: 0, 0, 0, 0, 0, 0, 0, 23.45, 0, 0, 0, 23.45, 0, 0, 0, 0, 0\n",
      "Parsed response: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.45, 0.0, 0.0, 0.0, 23.45, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Model response: 0, 0, 0, 0, 0, 0, 0, 0, 54.67, 0, 0, 0, 54.67, 0, 0, 0, 0\n",
      "Parsed response: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 54.67, 0.0, 0.0, 0.0, 54.67, 0.0, 0.0, 0.0, 0.0]\n",
      "Model response: 0, 0, 0, 0, 0, 0, 0, 0, 27.34, 0, 0, 0, 27.34, 0, 0, 0, 0\n",
      "Parsed response: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 27.34, 0.0, 0.0, 0.0, 27.34, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 45.6582145690918, 0.0, 0.0, 0.0, 44.660728454589844, 0.0, 0.0, 0.0, 0.0] [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.816666666666666, 27.33666666666667, 0.0, 0.0, 7.816666666666666, 27.33666666666667, 0.0, 0.0, 0.0, 0.0]\n",
      "Please predict the activation on this sentence,responding with a list of 17 numbers between 0 and 54.67.\n",
      "Sentence: \" See our privacy notice Could not subscribe, try again later Invalid EmailĊĊANGR\"\n",
      "Tokens:\n",
      " See\n",
      " our\n",
      " privacy\n",
      " notice\n",
      " Could\n",
      " not\n",
      " subscribe\n",
      ",\n",
      " try\n",
      " again\n",
      " later\n",
      " Invalid\n",
      " Email\n",
      "Ċ\n",
      "Ċ\n",
      "AN\n",
      "GR\n",
      "Remember, the english description of the feature is: \"occurrences of the word \"try\"\"\n",
      "Model response: 0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "54.67\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "Parsed response: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 54.67, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Model response: 0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "54.67\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "Parsed response: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 54.67, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Model response: 0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "54.67\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "Parsed response: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 54.67, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 49.46665954589844, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 54.669999999999995, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Please predict the activation on this sentence,responding with a list of 17 numbers between 0 and 54.67.\n",
      "Sentence: \", Arise, and take up your couch, and go into your house.\" (\"\n",
      "Tokens:\n",
      ",\n",
      " Ar\n",
      "ise\n",
      ",\n",
      " and\n",
      " take\n",
      " up\n",
      " your\n",
      " couch\n",
      ",\n",
      " and\n",
      " go\n",
      " into\n",
      " your\n",
      " house\n",
      ".\"\n",
      " (\n",
      "Remember, the english description of the feature is: \"occurrences of the word \"try\"\"\n",
      "Model response: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "Parsed response: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Model response: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "Parsed response: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Model response: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "Parsed response: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Please predict the activation on this sentence,responding with a list of 17 numbers between 0 and 54.67.\n",
      "Sentence: \" - which is North Korea's only major ally - was \"now working with other members\"\n",
      "Tokens:\n",
      " -\n",
      " which\n",
      " is\n",
      " North\n",
      " Korea\n",
      "'s\n",
      " only\n",
      " major\n",
      " ally\n",
      " -\n",
      " was\n",
      " \"\n",
      "now\n",
      " working\n",
      " with\n",
      " other\n",
      " members\n",
      "Remember, the english description of the feature is: \"occurrences of the word \"try\"\"\n",
      "Model response: 0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "Parsed response: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Model response: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "Parsed response: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Model response: 0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "Parsed response: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Please predict the activation on this sentence,responding with a list of 17 numbers between 0 and 54.67.\n",
      "Sentence: \" those concerning the alleged rampant corruption in FIFA biddings and the labor rights violation in\"\n",
      "Tokens:\n",
      " those\n",
      " concerning\n",
      " the\n",
      " alleged\n",
      " rampant\n",
      " corruption\n",
      " in\n",
      " FIFA\n",
      " b\n",
      "idd\n",
      "ings\n",
      " and\n",
      " the\n",
      " labor\n",
      " rights\n",
      " violation\n",
      " in\n",
      "Remember, the english description of the feature is: \"occurrences of the word \"try\"\"\n",
      "Model response: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "Parsed response: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Model response: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "Parsed response: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Model response: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "Parsed response: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Please predict the activation on this sentence,responding with a list of 17 numbers between 0 and 54.67.\n",
      "Sentence: \" perception of luxury to sell at higher prices aboard, also suffered from cheap fake products at\"\n",
      "Tokens:\n",
      " perception\n",
      " of\n",
      " luxury\n",
      " to\n",
      " sell\n",
      " at\n",
      " higher\n",
      " prices\n",
      " aboard\n",
      ",\n",
      " also\n",
      " suffered\n",
      " from\n",
      " cheap\n",
      " fake\n",
      " products\n",
      " at\n",
      "Remember, the english description of the feature is: \"occurrences of the word \"try\"\"\n",
      "Model response: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "Parsed response: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Model response: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "Parsed response: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Model response: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "Parsed response: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Please predict the activation on this sentence,responding with a list of 17 numbers between 0 and 54.67.\n",
      "Sentence: \" quitting to be replaced by the boss of parent group Fiat FIA.MI after the two\"\n",
      "Tokens:\n",
      " quitting\n",
      " to\n",
      " be\n",
      " replaced\n",
      " by\n",
      " the\n",
      " boss\n",
      " of\n",
      " parent\n",
      " group\n",
      " Fiat\n",
      " FIA\n",
      ".\n",
      "MI\n",
      " after\n",
      " the\n",
      " two\n",
      "Remember, the english description of the feature is: \"occurrences of the word \"try\"\"\n",
      "Model response: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Parsed response: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Model response: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Parsed response: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Model response: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Parsed response: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "predictions, extra_data = predict_activations('6-res-jb_subset_100/681.json', test_pos=5, test_neg=5, show_pos=0, show_neg=0, binary_class=False, all_tokens=True, neg_type='others', show_max_token=False, num_completions=3, debug=True, randomize_pos=True, model=\"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[([0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   49.46665954589844,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0],\n",
       "  [0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   33.47,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0]),\n",
       " ([0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   17.077308654785156,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0],\n",
       "  [0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   45.48666666666667,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0]),\n",
       " ([0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   49.46665954589844,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0],\n",
       "  [0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   54.669999999999995,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0]),\n",
       " ([0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   45.6582145690918,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   44.660728454589844,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0],\n",
       "  [0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   7.816666666666666,\n",
       "   27.33666666666667,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   7.816666666666666,\n",
       "   27.33666666666667,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0]),\n",
       " ([0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   49.46665954589844,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0],\n",
       "  [0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   54.669999999999995,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0]),\n",
       " ([0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0],\n",
       "  [0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0]),\n",
       " ([0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0],\n",
       "  [0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0]),\n",
       " ([0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0],\n",
       "  [0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0]),\n",
       " ([0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0],\n",
       "  [0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0]),\n",
       " ([0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0],\n",
       "  [0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0])]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run an experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = run_experiments(\n",
    "    num_features=2, \n",
    "    layer=6,\n",
    "    basis='res-jb',\n",
    "    test_pos=4, # Experiment with\n",
    "    test_neg=4, # Experiment with\n",
    "    show_pos=0, # Experiment with\n",
    "    show_neg=0, # Experiment with\n",
    "    neg_type='others', # Experiment with\n",
    "    binary_class=False, # Experiment with\n",
    "    all_tokens=True,\n",
    "    show_max_token=False, # Experiment with\n",
    "    num_completions=3, # Experiment with\n",
    "    debug=True, \n",
    "    randomize_pos=True, \n",
    "    save_location='test',\n",
    "    feature_ids=indices\n",
    ")\n",
    "\n",
    "# # the run_experiments function automatically saves results to results/exp_{timestamp}.json\n",
    "pprint.pprint(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the JSON file\n",
    "with open('6-res-jb_subset_100/428.json', 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Print the JSON structure\n",
    "print_json_tree(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do analysis on loaded json_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_data_binary = load_json_results('results/binary_test/exp_binary_others.json')\n",
    "json_data_continuous = load_json_results('results/binary_test/exp_continuous_others.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_preds = [json_data_binary['results'][i]['gpt_predictions'] for i in range(len(json_data_binary['results']))]\n",
    "continuous_preds = [json_data_continuous['results'][i]['gpt_predictions'] for i in range(len(json_data_continuous['results']))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = get_binary_accuracy(binary_preds, plot_cdf=True, plot_distribution=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_descs = get_accuracy_descs(json_data_binary, include_pos_neg=True, display=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resave_organized_modeldata(autoencoder_layers = [6],\n",
    "                        autoencoder_bases = [\n",
    "                            'neurons',\n",
    "                            'res-jb',])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "local_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
