{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from analyze_results import *\n",
    "from getting_examples import *\n",
    "from predict_activations import *\n",
    "from model_utils import *\n",
    "from utils import *\n",
    "import json\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/feature_benchmark/feat_bench/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gpt2-small into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "sae, model = load_sae_and_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2350.json gathered 10 other_negative activations\n",
      "23251.json gathered 10 other_negative activations\n",
      "11000.json gathered 10 other_negative activations\n",
      "13627.json gathered 10 other_negative activations\n",
      "21896.json gathered 10 other_negative activations\n",
      "WARNING: Resampling negative activation\n",
      "6332.json gathered 10 other_negative activations\n",
      "2534.json gathered 10 other_negative activations\n",
      "11263.json gathered 10 other_negative activations\n",
      "8913.json gathered 10 other_negative activations\n",
      "9532.json gathered 10 other_negative activations\n",
      "5128.json gathered 10 other_negative activations\n",
      "5157.json gathered 10 other_negative activations\n",
      "15162.json gathered 10 other_negative activations\n",
      "12092.json gathered 10 other_negative activations\n",
      "19697.json gathered 10 other_negative activations\n",
      "15570.json gathered 10 other_negative activations\n",
      "21983.json gathered 10 other_negative activations\n",
      "3230.json gathered 10 other_negative activations\n",
      "20780.json gathered 10 other_negative activations\n",
      "10322.json gathered 10 other_negative activations\n",
      "WARNING: Resampling negative activation\n",
      "7428.json gathered 10 other_negative activations\n",
      "10949.json gathered 10 other_negative activations\n",
      "11451.json gathered 10 other_negative activations\n",
      "16697.json gathered 10 other_negative activations\n",
      "WARNING: Resampling negative activation\n",
      "WARNING: Resampling negative activation\n",
      "6750.json gathered 10 other_negative activations\n",
      "19453.json gathered 10 other_negative activations\n",
      "23607.json gathered 10 other_negative activations\n",
      "1346.json gathered 10 other_negative activations\n",
      "4730.json gathered 10 other_negative activations\n",
      "WARNING: Resampling negative activation\n",
      "WARNING: Resampling negative activation\n",
      "21772.json gathered 10 other_negative activations\n",
      "11817.json gathered 10 other_negative activations\n",
      "WARNING: Resampling negative activation\n",
      "20963.json gathered 10 other_negative activations\n",
      "17386.json gathered 10 other_negative activations\n",
      "20351.json gathered 10 other_negative activations\n",
      "20820.json gathered 10 other_negative activations\n",
      "3096.json gathered 10 other_negative activations\n",
      "4634.json gathered 10 other_negative activations\n",
      "2830.json gathered 10 other_negative activations\n",
      "11212.json gathered 10 other_negative activations\n",
      "16183.json gathered 10 other_negative activations\n",
      "10404.json gathered 10 other_negative activations\n",
      "WARNING: Resampling negative activation\n",
      "WARNING: Resampling negative activation\n",
      "WARNING: Resampling negative activation\n",
      "8064.json gathered 10 other_negative activations\n",
      "14882.json gathered 10 other_negative activations\n",
      "6448.json gathered 10 other_negative activations\n",
      "14583.json gathered 10 other_negative activations\n",
      "1103.json gathered 10 other_negative activations\n",
      "10075.json gathered 10 other_negative activations\n",
      "5625.json gathered 10 other_negative activations\n",
      "WARNING: Resampling negative activation\n",
      "9760.json gathered 10 other_negative activations\n",
      "3594.json gathered 10 other_negative activations\n",
      "20189.json gathered 10 other_negative activations\n",
      "2004.json gathered 10 other_negative activations\n",
      "11264.json gathered 10 other_negative activations\n",
      "8685.json gathered 10 other_negative activations\n",
      "16693.json gathered 10 other_negative activations\n",
      "7476.json gathered 10 other_negative activations\n",
      "WARNING: Resampling negative activation\n",
      "16596.json gathered 10 other_negative activations\n",
      "11799.json gathered 10 other_negative activations\n",
      "13133.json gathered 10 other_negative activations\n",
      "9658.json gathered 10 other_negative activations\n",
      "1202.json gathered 10 other_negative activations\n",
      "12694.json gathered 10 other_negative activations\n",
      "14524.json gathered 10 other_negative activations\n",
      "WARNING: Resampling negative activation\n",
      "WARNING: Resampling negative activation\n",
      "WARNING: Resampling negative activation\n",
      "4036.json gathered 10 other_negative activations\n",
      "19899.json gathered 10 other_negative activations\n",
      "4679.json gathered 10 other_negative activations\n",
      "WARNING: Resampling negative activation\n",
      "14073.json gathered 10 other_negative activations\n",
      "14372.json gathered 10 other_negative activations\n",
      "14610.json gathered 10 other_negative activations\n",
      "15500.json gathered 10 other_negative activations\n",
      "21032.json gathered 10 other_negative activations\n",
      "752.json gathered 10 other_negative activations\n",
      "18083.json gathered 10 other_negative activations\n",
      "7739.json gathered 10 other_negative activations\n",
      "11606.json gathered 10 other_negative activations\n",
      "3197.json gathered 10 other_negative activations\n",
      "14169.json gathered 10 other_negative activations\n",
      "WARNING: Resampling negative activation\n",
      "19484.json gathered 10 other_negative activations\n",
      "22719.json gathered 10 other_negative activations\n",
      "8728.json gathered 10 other_negative activations\n",
      "7104.json gathered 10 other_negative activations\n",
      "14931.json gathered 10 other_negative activations\n",
      "WARNING: Resampling negative activation\n",
      "22832.json gathered 10 other_negative activations\n",
      "2858.json gathered 10 other_negative activations\n",
      "9002.json gathered 10 other_negative activations\n",
      "536.json gathered 10 other_negative activations\n",
      "7585.json gathered 10 other_negative activations\n",
      "WARNING: Resampling negative activation\n",
      "17533.json gathered 10 other_negative activations\n",
      "WARNING: Resampling negative activation\n",
      "428.json gathered 10 other_negative activations\n",
      "19505.json gathered 10 other_negative activations\n",
      "6769.json gathered 10 other_negative activations\n",
      "2726.json gathered 10 other_negative activations\n",
      "13410.json gathered 10 other_negative activations\n",
      "22202.json gathered 10 other_negative activations\n",
      "3509.json gathered 10 other_negative activations\n",
      "9579.json gathered 10 other_negative activations\n",
      "681.json gathered 10 other_negative activations\n",
      "22138.json gathered 10 other_negative activations\n",
      "WARNING: Resampling negative activation\n",
      "21380.json gathered 10 other_negative activations\n",
      "15824.json gathered 10 other_negative activations\n"
     ]
    }
   ],
   "source": [
    "recompute_directory_activations('6-res-jb_subset_100', 'gpt2-small-organized/6-res-jb', model, sae, recompute=False, re_sort=False, num_neg_others=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_id = 1\n",
    "\n",
    "description, pos_examples, neg_examples, highest_activation = get_pos_neg_examples(feat_id, layer=6, basis='res-jb', num_pos=2, num_neg=2, neg_type='others', randomize_pos_examples=False)\n",
    "print(description)\n",
    "\n",
    "max_indices = [pos_examples[i]['max_value_token_index'] + 1 for i in range(len(pos_examples))] + [9 for i in range(len(neg_examples))]\n",
    "strings = [pos_examples[i]['sentence_string'] for i in range(len(pos_examples))] + [neg_examples[i]['sentence_string'] for i in range(len(neg_examples))]\n",
    "\n",
    "for pos in pos_examples:\n",
    "    print(pos['sentence_string'])\n",
    "    print(pos['values'])\n",
    "\n",
    "for neg in neg_examples:\n",
    "    print(neg['sentence_string'])\n",
    "    print(neg['values'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_acts, inner_acts, post_acts = get_sae_activations(model, sae, strings)\n",
    "\n",
    "for inner_act in inner_acts:\n",
    "    x = np.array(inner_act)\n",
    "    print(x[:,feat_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get model's loss on strings\n",
    "regular_losses = get_vanilla_loss(model, sae, strings)\n",
    "print(pretty_losses_fmt(\"Regular\", strings, regular_losses))\n",
    "\n",
    "# Get model's loss on strings using SAE reconstructed activations\n",
    "sae_losses = get_vanilla_loss(model, sae, strings, with_sae_replacement=True)\n",
    "print(pretty_losses_fmt(\"SAE\", strings, sae_losses))\n",
    "\n",
    "# Loss with all features ablated\n",
    "precomputed_zeros = [[[0.0] * len(l) for l in seq] for seq in inner_acts]\n",
    "zeros_losses = get_recons_loss_from_predicted_values(model, sae, strings, precomputed_zeros)\n",
    "print(pretty_losses_fmt(\"Zeros\", strings, zeros_losses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get model's loss on strings using SAE with selected feature ablated\n",
    "replacements = [0 for string in strings]\n",
    "ablated_inner_acts = replace_max_feature_activation(inner_acts, feat_id, max_indices, replacements)\n",
    "ablated_sae_losses = get_recons_loss_from_predicted_values(model, sae, strings, ablated_inner_acts)\n",
    "print(pretty_losses_fmt(f\"SAE feature {feat_id} ablated\", strings, ablated_sae_losses))\n",
    "\n",
    "for inner_act in ablated_inner_acts:\n",
    "    x = np.array(inner_act)\n",
    "    print(x[:,feat_id])\n",
    "\n",
    "# Print how much loss changes after ablating selected feature\n",
    "difference = elementwise_difference(sae_losses, ablated_sae_losses)\n",
    "rounded_difference = [[round(elem, 2) for elem in sublist] for sublist in difference]\n",
    "print(rounded_difference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "indices = list(map(int, np.random.choice(24576, size=100, replace=False)))\n",
    "print(indices)\n",
    "# copy_files_by_list(indices, 'gpt2-small-organized/6-res-jb', '6-res-jb_subset_100')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run an experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = run_experiments(\n",
    "    num_features=2, \n",
    "    layer=6,\n",
    "    basis='res-jb',\n",
    "    test_pos=4, # Experiment with\n",
    "    test_neg=4, # Experiment with\n",
    "    show_pos=0, # Experiment with\n",
    "    show_neg=0, # Experiment with\n",
    "    neg_type='others', # Experiment with\n",
    "    binary_class=False, # Experiment with\n",
    "    all_tokens=True,\n",
    "    show_max_token=False, # Experiment with\n",
    "    num_completions=3, # Experiment with\n",
    "    debug=True, \n",
    "    randomize_pos=True, \n",
    "    save_location='test',\n",
    "    feature_ids=indices\n",
    ")\n",
    "\n",
    "# # the run_experiments function automatically saves results to results/exp_{timestamp}.json\n",
    "pprint.pprint(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the JSON file\n",
    "with open('6-res-jb_subset_100/428.json', 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Print the JSON structure\n",
    "print_json_tree(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do analysis on loaded json_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_data_binary = load_json_results('results/binary_test/exp_binary_others.json')\n",
    "json_data_continuous = load_json_results('results/binary_test/exp_continuous_others.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_preds = [json_data_binary['results'][i]['gpt_predictions'] for i in range(len(json_data_binary['results']))]\n",
    "continuous_preds = [json_data_continuous['results'][i]['gpt_predictions'] for i in range(len(json_data_continuous['results']))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = get_binary_accuracy(binary_preds, plot_cdf=True, plot_distribution=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_descs = get_accuracy_descs(json_data_binary, include_pos_neg=True, display=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resave_organized_modeldata(autoencoder_layers = [6],\n",
    "                        autoencoder_bases = [\n",
    "                            'neurons',\n",
    "                            'res-jb',])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "local_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
